{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3e3c91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c3e3c91",
    "outputId": "b83c5e3a-9c26-43e0-e305-40efe274fa1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scattering-transform in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (0.0.7)\n",
      "Requirement already satisfied: torch in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from scattering-transform) (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from torch->scattering-transform) (3.10.0.2)\n",
      "Requirement already satisfied: transformers in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (4.19.0.dev0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: sacremoses in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: numpy>=1.17 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: joblib in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /common/home/ab2253/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scattering-transform\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04621834",
   "metadata": {
    "id": "04621834"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scattering_transform import SCL, SCLTrainingWrapper\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d228b",
   "metadata": {
    "id": "525d228b"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f40809",
   "metadata": {
    "id": "72f40809"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, root_dir, dataset_type, img_size, transform=None, shuffle=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.file_names = [f for f in glob.glob(os.path.join(root_dir, \"*\", \"*.npz\")) \\\n",
    "                            if dataset_type in f]\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.file_names[idx]\n",
    "        data = np.load(data_path)\n",
    "        image = data[\"image\"].reshape(16, 160, 160)\n",
    "        target = data[\"target\"]\n",
    "        structure = data[\"structure\"]\n",
    "        meta_target = data[\"meta_target\"]\n",
    "        meta_structure = data[\"meta_structure\"]\n",
    "\n",
    "        if self.shuffle:\n",
    "            context = image[:8, :, :]\n",
    "            choices = image[8:, :, :]\n",
    "            indices = list(range(8))\n",
    "            np.random.shuffle(indices)\n",
    "            new_target = indices.index(target)\n",
    "            new_choices = choices[indices, :, :]\n",
    "            image = np.concatenate((context, new_choices))\n",
    "            target = new_target\n",
    "        \n",
    "        resize_image = []\n",
    "        for idx in range(0, 16):\n",
    "            resize_image.append(resize(image[idx,:,:], (self.img_size, self.img_size)))\n",
    "        resize_image = np.stack(resize_image)\n",
    "\n",
    "        embedding = torch.zeros((6, 300), dtype=torch.float)\n",
    "        indicator = torch.zeros(1, dtype=torch.float)\n",
    "        element_idx = 0\n",
    "    \n",
    "        del data\n",
    "        if self.transform:\n",
    "            resize_image = self.transform(resize_image)\n",
    "            target = torch.tensor(target, dtype=torch.long)\n",
    "            meta_target = self.transform(meta_target)\n",
    "            meta_structure = self.transform(meta_structure)\n",
    "            meta_target = torch.tensor(meta_target, dtype=torch.long)\n",
    "        return resize_image, target, meta_target, meta_structure, embedding, indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b2e0d",
   "metadata": {
    "id": "525b2e0d"
   },
   "source": [
    "#### Experiment Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ff94ea",
   "metadata": {
    "id": "09ff94ea"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.model = 'ViT_SCL'\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 32\n",
    "        self.seed = 12345\n",
    "        self.device = 1\n",
    "        self.load_workers = 16\n",
    "        self.resume = False\n",
    "        self.path = '/common/home/ab2253/Desktop/data_new'\n",
    "        self.save = './ckpt_res/'\n",
    "        self.img_size = 80\n",
    "        self.lr = 1e-4\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.meta_alpha = 0.\n",
    "        self.meta_beta = 0.\n",
    "        self.perc_train = 100\n",
    "        self.verbose = False\n",
    "\n",
    "        # ViT parameters\n",
    "        self.vit_requires_grad = False\n",
    "        self.vec2image_input_dim = 768\n",
    "\n",
    "        # SCL Hyperparameters\n",
    "        self.scl_image_size = 224\n",
    "        self.scl_set_size = 9\n",
    "        self.scl_conv_channels = [1, 16, 16, 32, 32, 32]\n",
    "        self.scl_conv_output_dim = 80\n",
    "        self.scl_attr_heads = 10\n",
    "        self.scl_attr_net_hidden_dims = [128]\n",
    "        self.scl_rel_heads = 80\n",
    "        self.scl_rel_net_hidden_dims = [64, 23, 5]\n",
    "        \n",
    "args = Args()\n",
    "\n",
    "args.cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(args.device)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "if not os.path.exists(args.save):\n",
    "    os.makedirs(args.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6e886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df25649",
   "metadata": {
    "id": "2df25649"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12465577",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12465577",
    "outputId": "e132e359-402b-46cc-f869-198e3ff1f502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in original train set = 24000\n",
      "Number of samples in train subset = 24000\n",
      "All samples are unique = True\n"
     ]
    }
   ],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        return torch.tensor(sample, dtype=torch.float32)\n",
    "\n",
    "train = dataset(args.path, \"train\", args.img_size, transform=transforms.Compose([ToTensor()]),shuffle=True)\n",
    "valid = dataset(args.path, \"val\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "test = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "subset_indices = np.random.choice(len(train), len(train)*args.perc_train // 100, replace=False)\n",
    "train_subset = Subset(train, subset_indices)\n",
    "\n",
    "print(\"Number of samples in original train set =\", len(train))\n",
    "print(\"Number of samples in train subset =\", len(train_subset))\n",
    "print(\"All samples are unique =\", len(subset_indices) == len(set(subset_indices)))\n",
    "\n",
    "trainloader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=True, num_workers=16)\n",
    "validloader = DataLoader(valid, batch_size=args.batch_size, shuffle=False, num_workers=16)\n",
    "testloader = DataLoader(test, batch_size=args.batch_size, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c5e42",
   "metadata": {
    "id": "137c5e42"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fceea95",
   "metadata": {
    "id": "0fceea95"
   },
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.name = args.model\n",
    "    \n",
    "    def load_model(self, path, epoch):\n",
    "        state_dict = torch.load(path+'{}_epoch_{}.pth'.format(self.name, epoch))['state_dict']\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def save_model(self, path, epoch, acc, loss):\n",
    "        torch.save({'state_dict': self.state_dict(), 'acc': acc, 'loss': loss}, path+'{}_epoch_{}.pth'.format(self.name, epoch))\n",
    "\n",
    "    def compute_loss(self, output, target, meta_target, meta_structure):\n",
    "        pass\n",
    "\n",
    "    def train_(self, image, target, meta_target, meta_structure, embedding, indicator):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self(image, embedding, indicator)\n",
    "        loss = self.compute_loss(output, target, meta_target, meta_structure)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        pred = output[0].data.max(1)[1]\n",
    "        correct = pred.eq(target.data).cpu().sum().numpy()\n",
    "        accuracy = correct * 100.0 / target.size()[0]\n",
    "        return loss.item(), accuracy\n",
    "\n",
    "    def validate_(self, image, target, meta_target, meta_structure, embedding, indicator):\n",
    "        with torch.no_grad():\n",
    "            output = self(image, embedding, indicator)\n",
    "        loss = self.compute_loss(output, target, meta_target, meta_structure)\n",
    "        pred = output[0].data.max(1)[1]\n",
    "        correct = pred.eq(target.data).cpu().sum().numpy()\n",
    "        accuracy = correct * 100.0 / target.size()[0]\n",
    "        return loss.item(), accuracy\n",
    "\n",
    "    def test_(self, image, target, meta_target, meta_structure, embedding, indicator):\n",
    "        with torch.no_grad():\n",
    "            output = self(image, embedding, indicator)\n",
    "        pred = output[0].data.max(1)[1]\n",
    "        correct = pred.eq(target.data).cpu().sum().numpy()\n",
    "        accuracy = correct * 100.0 / target.size()[0]\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "GFfD1_nM2g4u",
   "metadata": {
    "id": "GFfD1_nM2g4u"
   },
   "outputs": [],
   "source": [
    "def zeros(shape):\n",
    "    return nn.init.zeros_(torch.empty(shape))\n",
    "\n",
    "def glorot(shape):\n",
    "    return nn.init.xavier_uniform_(torch.empty(shape), gain=1.)\n",
    "\n",
    "class Vec2Image(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, bias=True, act=F.relu):\n",
    "        super(Vec2Image, self).__init__()\n",
    "\n",
    "        if len(output_dim) != 3:\n",
    "            raise ValueError(\"output_dim must be 3d.\")\n",
    "\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.act = act\n",
    "\n",
    "        self.weight = nn.Parameter(glorot((input_dim, output_dim[1]*output_dim[2])))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(zeros((output_dim[1]*output_dim[2])))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expected shape of x: (b, n)\n",
    "\n",
    "        x = self.act(torch.matmul(x, self.weight) + self.bias)\n",
    "        x = x.view((x.shape[0] // 8, 8, 1, self.output_dim[1], self.output_dim[2]))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be4b72",
   "metadata": {
    "id": "67be4b72"
   },
   "source": [
    "#### Vision Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6QqNvG_q4dvY",
   "metadata": {
    "id": "6QqNvG_q4dvY"
   },
   "outputs": [],
   "source": [
    "TO_IMG = transforms.ToPILImage()\n",
    "\n",
    "def to_image(b):\n",
    "    b = b.reshape((b.shape[0]*b.shape[1], 1, b.shape[2], b.shape[3]))\n",
    "    trans_b = [TO_IMG(x) for x in b]\n",
    "    return trans_b\n",
    "\n",
    "class ViTSCL(BasicModel):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(ViTSCL, self).__init__(args)\n",
    "\n",
    "        self.id2label = {'opt' + str(k): k for k in range(8)}\n",
    "        self.label2id = {k: 'opt' + str(k) for k in range(8)}\n",
    "\n",
    "        self.encoder = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k',\n",
    "                                                                num_labels=8,\n",
    "                                                                id2label=self.id2label,\n",
    "                                                                label2id=self.label2id,\n",
    "                                                                output_hidden_states=True) \n",
    "\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.requires_grad = args.vit_requires_grad\n",
    "\n",
    "        self.vec2image = Vec2Image(input_dim=args.vec2image_input_dim, output_dim=(1, args.scl_image_size, args.scl_image_size))\n",
    "\n",
    "        self.scl = SCL(\n",
    "            image_size = args.scl_image_size,                           # size of image\n",
    "            set_size = args.scl_set_size,                               # number of questions + 1 answer\n",
    "            conv_channels = args.scl_conv_channels,                     # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "            conv_output_dim = args.scl_conv_output_dim,                 # model dimension, the output dimension of the vision net\n",
    "            attr_heads = args.scl_attr_heads,                           # number of attribute heads\n",
    "            attr_net_hidden_dims = args.scl_attr_net_hidden_dims,       # attribute scatter transform MLP hidden dimension(s)\n",
    "            rel_heads = args.scl_rel_heads,                             # number of relationship heads\n",
    "            rel_net_hidden_dims = args.scl_rel_net_hidden_dims          # MLP for relationship net\n",
    "        )\n",
    "\n",
    "        self.decoder = SCLTrainingWrapper(self.scl)\n",
    "\n",
    "        self.verbose = args.verbose\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr, betas=(args.beta1, args.beta2), eps=args.epsilon)\n",
    "        \n",
    "        #self.Linear1 = torch.nn.Linear(768,768)\n",
    "        #self.Linear2 = torch.nn.Linear(768,768)\n",
    "        #self.Linear3 = torch.nn.Linear(768,768)\n",
    "        #self.Linear4 = torch.nn.Linear(768,768)\n",
    "        \n",
    "        # Transforms\n",
    "        self.grayscale_to_rgb = transforms.Lambda(lambda x: x.reshape((1, x.shape[0], x.shape[1])).repeat(3, 1, 1))\n",
    "        self.reshape_input_batch = transforms.Lambda(lambda x: x.reshape((x.shape[0]*x.shape[1], x.shape[2], x.shape[3])))\n",
    "        self.resize_to_vit_size = transforms.Resize((224, 224))\n",
    "        \n",
    "    def compute_loss(self, output, target, meta_target, meta_structure):\n",
    "        pred = output[0]\n",
    "        loss = F.cross_entropy(pred, target)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, embedding, indicator):\n",
    "        questions = x[:, :8, :, :]\n",
    "        answers = x[:, 8:, :, :]\n",
    "\n",
    "        q = self.reshape_input_batch(questions)\n",
    "        a = self.reshape_input_batch(answers)\n",
    "\n",
    "        q = torch.stack([self.resize_to_vit_size(self.grayscale_to_rgb(x)) for x in q])\n",
    "        a = torch.stack([self.resize_to_vit_size(self.grayscale_to_rgb(x)) for x in a])\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Shape of q =\", q.shape)\n",
    "            print(\"Shape of a =\", q.shape)\n",
    "\n",
    "        q_vit = self.encoder(q)['hidden_states'][-1][:, 0, :]\n",
    "        a_vit = self.encoder(a)['hidden_states'][-1][:, 0, :]\n",
    "        \n",
    "        #q_vit = self.Linear1(q_vit)\n",
    "        #q_vit = self.Linear2(q_vit)\n",
    "        \n",
    "        #a_vit = self.Linear1(a_vit)\n",
    "        #a_vit = self.Linear2(a_vit)\n",
    "        \n",
    "        q_imgs = self.vec2image(q_vit)\n",
    "        a_imgs = self.vec2image(a_vit)\n",
    "\n",
    "        logits = self.decoder(q_imgs, a_imgs)\n",
    "\n",
    "        return logits, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eed74b",
   "metadata": {
    "id": "c5eed74b"
   },
   "source": [
    "### Training and Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4a7df7",
   "metadata": {
    "id": "eb4a7df7"
   },
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "def train(epoch, save_file):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "    loss_all = 0.0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target, meta_structure, embedding, indicator) in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "            meta_structure = meta_structure.cuda()\n",
    "            embedding = embedding.cuda()\n",
    "            indicator = indicator.cuda()\n",
    "        loss, acc = model.train_(image, target, meta_target, meta_structure, embedding, indicator)\n",
    "        save_str = 'Train: Epoch:{}, Batch:{}, Loss:{:.6f}, Acc:{:.4f}'.format(epoch, batch_idx, loss, acc)\n",
    "        if counter % 20 == 0:\n",
    "            print(save_str)\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write(save_str + \"\\n\")\n",
    "        loss_all += loss\n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        save_str = \"Train_: Avg Training Loss: {:.6f}, Avg Training Acc: {:.6f}\".format(\n",
    "            loss_all/float(counter),\n",
    "            (acc_all/float(counter))\n",
    "        )\n",
    "        print(save_str)\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write(save_str + \"\\n\")\n",
    "    return loss_all/float(counter), acc_all/float(counter)\n",
    "\n",
    "def validate(epoch, save_file):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    loss_all = 0.0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    batch_idx = 0\n",
    "    for batch_idx, (image, target, meta_target, meta_structure, embedding, indicator) in enumerate(validloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "            meta_structure = meta_structure.cuda()\n",
    "            embedding = embedding.cuda()\n",
    "            indicator = indicator.cuda()\n",
    "        loss, acc = model.validate_(image, target, meta_target, meta_structure, embedding, indicator)\n",
    "        loss_all += loss\n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        save_str = \"Val_: Total Validation Loss: {:.6f}, Acc: {:.4f}\".format((loss_all/float(counter)), (acc_all/float(counter)))\n",
    "        print(save_str)\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write(save_str + \"\\n\")\n",
    "    return loss_all/float(counter), acc_all/float(counter)\n",
    "\n",
    "def test(epoch, save_file):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target, meta_structure, embedding, indicator) in enumerate(testloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "            meta_structure = meta_structure.cuda()\n",
    "            embedding = embedding.cuda()\n",
    "            indicator = indicator.cuda()\n",
    "        acc = model.test_(image, target, meta_target, meta_structure, embedding, indicator)\n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        save_str = \"Test_: Total Testing Acc: {:.4f}\".format((acc_all / float(counter)))\n",
    "        print(save_str)\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write(save_str + \"\\n\")\n",
    "    return acc_all/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f1dba7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35f1dba7",
    "outputId": "21419531-f91b-4fe7-a09e-cea553793330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 s, sys: 4.09 s, total: 52.2 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = ViTSCL(args)\n",
    "model = model.cuda()\n",
    "#model = torch.nn.DataParallel(model, device_ids=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fbb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model(\"/common/home/ab2253/Desktop/ckpt_res/\", \"42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0b65a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cf0b65a",
    "outputId": "a43dfb08-fb26-4c12-f161-d83bffa20114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:0, Batch:19, Loss:0.285534, Acc:84.3750\n",
      "Train: Epoch:0, Batch:39, Loss:0.165335, Acc:93.7500\n",
      "Train: Epoch:0, Batch:59, Loss:0.477421, Acc:90.6250\n",
      "Train: Epoch:0, Batch:79, Loss:0.141237, Acc:100.0000\n",
      "Train: Epoch:0, Batch:99, Loss:0.313336, Acc:90.6250\n",
      "Train: Epoch:0, Batch:119, Loss:0.136612, Acc:93.7500\n",
      "Train: Epoch:0, Batch:139, Loss:0.175871, Acc:90.6250\n",
      "Train: Epoch:0, Batch:159, Loss:0.227976, Acc:93.7500\n",
      "Train: Epoch:0, Batch:179, Loss:0.102543, Acc:93.7500\n",
      "Train: Epoch:0, Batch:199, Loss:0.258211, Acc:87.5000\n",
      "Train: Epoch:0, Batch:219, Loss:0.303621, Acc:87.5000\n",
      "Train: Epoch:0, Batch:239, Loss:0.115665, Acc:93.7500\n",
      "Train: Epoch:0, Batch:259, Loss:0.149667, Acc:93.7500\n",
      "Train: Epoch:0, Batch:279, Loss:0.310863, Acc:90.6250\n",
      "Train: Epoch:0, Batch:299, Loss:0.191723, Acc:96.8750\n",
      "Train: Epoch:0, Batch:319, Loss:0.469431, Acc:84.3750\n",
      "Train: Epoch:0, Batch:339, Loss:0.210024, Acc:96.8750\n",
      "Train: Epoch:0, Batch:359, Loss:0.234836, Acc:93.7500\n",
      "Train: Epoch:0, Batch:379, Loss:0.323543, Acc:87.5000\n",
      "Train: Epoch:0, Batch:399, Loss:0.246034, Acc:93.7500\n",
      "Train: Epoch:0, Batch:419, Loss:0.181393, Acc:90.6250\n",
      "Train: Epoch:0, Batch:439, Loss:0.171833, Acc:93.7500\n",
      "Train: Epoch:0, Batch:459, Loss:0.334591, Acc:84.3750\n",
      "Train: Epoch:0, Batch:479, Loss:0.100289, Acc:96.8750\n",
      "Train: Epoch:0, Batch:499, Loss:0.122339, Acc:96.8750\n",
      "Train: Epoch:0, Batch:519, Loss:0.234194, Acc:90.6250\n",
      "Train: Epoch:0, Batch:539, Loss:0.225850, Acc:87.5000\n",
      "Train: Epoch:0, Batch:559, Loss:0.181257, Acc:90.6250\n",
      "Train: Epoch:0, Batch:579, Loss:0.216084, Acc:96.8750\n",
      "Train: Epoch:0, Batch:599, Loss:0.290548, Acc:81.2500\n",
      "Train: Epoch:0, Batch:619, Loss:0.084552, Acc:100.0000\n",
      "Train: Epoch:0, Batch:639, Loss:0.059968, Acc:96.8750\n",
      "Train: Epoch:0, Batch:659, Loss:0.128600, Acc:96.8750\n",
      "Train: Epoch:0, Batch:679, Loss:0.104396, Acc:96.8750\n",
      "Train: Epoch:0, Batch:699, Loss:0.241185, Acc:87.5000\n",
      "Train: Epoch:0, Batch:719, Loss:0.123925, Acc:96.8750\n",
      "Train: Epoch:0, Batch:739, Loss:0.098463, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.201964, Avg Training Acc: 92.229167\n",
      "Val_: Total Validation Loss: 1.207188, Acc: 70.8375\n",
      "Test_: Total Testing Acc: 70.7125\n",
      "Time taken = 1979.5398 s\n",
      "\n",
      "Train: Epoch:1, Batch:19, Loss:0.109404, Acc:96.8750\n",
      "Train: Epoch:1, Batch:39, Loss:0.187350, Acc:90.6250\n",
      "Train: Epoch:1, Batch:59, Loss:0.335667, Acc:87.5000\n",
      "Train: Epoch:1, Batch:79, Loss:0.275147, Acc:90.6250\n",
      "Train: Epoch:1, Batch:99, Loss:0.134063, Acc:90.6250\n",
      "Train: Epoch:1, Batch:119, Loss:0.284463, Acc:87.5000\n",
      "Train: Epoch:1, Batch:139, Loss:0.163961, Acc:93.7500\n",
      "Train: Epoch:1, Batch:159, Loss:0.210924, Acc:84.3750\n",
      "Train: Epoch:1, Batch:179, Loss:0.342670, Acc:87.5000\n",
      "Train: Epoch:1, Batch:199, Loss:0.140460, Acc:93.7500\n",
      "Train: Epoch:1, Batch:219, Loss:0.267956, Acc:93.7500\n",
      "Train: Epoch:1, Batch:239, Loss:0.083668, Acc:96.8750\n",
      "Train: Epoch:1, Batch:259, Loss:0.243392, Acc:90.6250\n",
      "Train: Epoch:1, Batch:279, Loss:0.131943, Acc:93.7500\n",
      "Train: Epoch:1, Batch:299, Loss:0.060599, Acc:100.0000\n",
      "Train: Epoch:1, Batch:319, Loss:0.311474, Acc:84.3750\n",
      "Train: Epoch:1, Batch:339, Loss:0.160026, Acc:93.7500\n",
      "Train: Epoch:1, Batch:359, Loss:0.265614, Acc:87.5000\n",
      "Train: Epoch:1, Batch:379, Loss:0.090756, Acc:100.0000\n",
      "Train: Epoch:1, Batch:399, Loss:0.131862, Acc:93.7500\n",
      "Train: Epoch:1, Batch:419, Loss:0.332567, Acc:90.6250\n",
      "Train: Epoch:1, Batch:439, Loss:0.251893, Acc:93.7500\n",
      "Train: Epoch:1, Batch:459, Loss:0.246643, Acc:90.6250\n",
      "Train: Epoch:1, Batch:479, Loss:0.208952, Acc:87.5000\n",
      "Train: Epoch:1, Batch:499, Loss:0.230026, Acc:90.6250\n",
      "Train: Epoch:1, Batch:519, Loss:0.146747, Acc:96.8750\n",
      "Train: Epoch:1, Batch:539, Loss:0.178911, Acc:93.7500\n",
      "Train: Epoch:1, Batch:559, Loss:0.165846, Acc:93.7500\n",
      "Train: Epoch:1, Batch:579, Loss:0.598032, Acc:81.2500\n",
      "Train: Epoch:1, Batch:599, Loss:0.342028, Acc:93.7500\n",
      "Train: Epoch:1, Batch:619, Loss:0.238212, Acc:87.5000\n",
      "Train: Epoch:1, Batch:639, Loss:0.272689, Acc:87.5000\n",
      "Train: Epoch:1, Batch:659, Loss:0.184053, Acc:90.6250\n",
      "Train: Epoch:1, Batch:679, Loss:0.205885, Acc:93.7500\n",
      "Train: Epoch:1, Batch:699, Loss:0.156452, Acc:93.7500\n",
      "Train: Epoch:1, Batch:719, Loss:0.435272, Acc:78.1250\n",
      "Train: Epoch:1, Batch:739, Loss:0.093052, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.199821, Avg Training Acc: 92.233333\n",
      "Val_: Total Validation Loss: 1.152925, Acc: 71.3250\n",
      "Test_: Total Testing Acc: 71.5875\n",
      "Time taken = 1995.7552 s\n",
      "\n",
      "Train: Epoch:2, Batch:19, Loss:0.256246, Acc:90.6250\n",
      "Train: Epoch:2, Batch:39, Loss:0.061305, Acc:96.8750\n",
      "Train: Epoch:2, Batch:59, Loss:0.063880, Acc:100.0000\n",
      "Train: Epoch:2, Batch:79, Loss:0.336123, Acc:93.7500\n",
      "Train: Epoch:2, Batch:99, Loss:0.100301, Acc:93.7500\n",
      "Train: Epoch:2, Batch:119, Loss:0.113434, Acc:100.0000\n",
      "Train: Epoch:2, Batch:139, Loss:0.179048, Acc:93.7500\n",
      "Train: Epoch:2, Batch:159, Loss:0.205405, Acc:90.6250\n",
      "Train: Epoch:2, Batch:179, Loss:0.171918, Acc:96.8750\n",
      "Train: Epoch:2, Batch:199, Loss:0.167556, Acc:93.7500\n",
      "Train: Epoch:2, Batch:219, Loss:0.066745, Acc:96.8750\n",
      "Train: Epoch:2, Batch:239, Loss:0.215130, Acc:93.7500\n",
      "Train: Epoch:2, Batch:259, Loss:0.176661, Acc:90.6250\n",
      "Train: Epoch:2, Batch:279, Loss:0.075719, Acc:96.8750\n",
      "Train: Epoch:2, Batch:299, Loss:0.125829, Acc:96.8750\n",
      "Train: Epoch:2, Batch:319, Loss:0.223229, Acc:90.6250\n",
      "Train: Epoch:2, Batch:339, Loss:0.147455, Acc:93.7500\n",
      "Train: Epoch:2, Batch:359, Loss:0.148624, Acc:90.6250\n",
      "Train: Epoch:2, Batch:379, Loss:0.204844, Acc:87.5000\n",
      "Train: Epoch:2, Batch:399, Loss:0.144557, Acc:93.7500\n",
      "Train: Epoch:2, Batch:419, Loss:0.183682, Acc:93.7500\n",
      "Train: Epoch:2, Batch:439, Loss:0.121990, Acc:96.8750\n",
      "Train: Epoch:2, Batch:459, Loss:0.153636, Acc:96.8750\n",
      "Train: Epoch:2, Batch:479, Loss:0.199345, Acc:93.7500\n",
      "Train: Epoch:2, Batch:499, Loss:0.476845, Acc:87.5000\n",
      "Train: Epoch:2, Batch:519, Loss:0.274159, Acc:87.5000\n",
      "Train: Epoch:2, Batch:539, Loss:0.221871, Acc:90.6250\n",
      "Train: Epoch:2, Batch:559, Loss:0.243229, Acc:87.5000\n",
      "Train: Epoch:2, Batch:579, Loss:0.131044, Acc:96.8750\n",
      "Train: Epoch:2, Batch:599, Loss:0.151803, Acc:93.7500\n",
      "Train: Epoch:2, Batch:619, Loss:0.196690, Acc:90.6250\n",
      "Train: Epoch:2, Batch:639, Loss:0.289591, Acc:90.6250\n",
      "Train: Epoch:2, Batch:659, Loss:0.104539, Acc:96.8750\n",
      "Train: Epoch:2, Batch:679, Loss:0.018304, Acc:100.0000\n",
      "Train: Epoch:2, Batch:699, Loss:0.188427, Acc:96.8750\n",
      "Train: Epoch:2, Batch:719, Loss:0.293345, Acc:81.2500\n",
      "Train: Epoch:2, Batch:739, Loss:0.177753, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.184194, Avg Training Acc: 92.804167\n",
      "Val_: Total Validation Loss: 1.191514, Acc: 71.5375\n",
      "Test_: Total Testing Acc: 71.4125\n",
      "Time taken = 1989.8694 s\n",
      "\n",
      "Train: Epoch:3, Batch:19, Loss:0.184617, Acc:87.5000\n",
      "Train: Epoch:3, Batch:39, Loss:0.259485, Acc:87.5000\n",
      "Train: Epoch:3, Batch:59, Loss:0.077513, Acc:100.0000\n",
      "Train: Epoch:3, Batch:79, Loss:0.395371, Acc:81.2500\n",
      "Train: Epoch:3, Batch:99, Loss:0.155040, Acc:93.7500\n",
      "Train: Epoch:3, Batch:119, Loss:0.055941, Acc:100.0000\n",
      "Train: Epoch:3, Batch:139, Loss:0.155417, Acc:93.7500\n",
      "Train: Epoch:3, Batch:159, Loss:0.079280, Acc:100.0000\n",
      "Train: Epoch:3, Batch:179, Loss:0.097250, Acc:93.7500\n",
      "Train: Epoch:3, Batch:199, Loss:0.076232, Acc:96.8750\n",
      "Train: Epoch:3, Batch:219, Loss:0.123826, Acc:93.7500\n",
      "Train: Epoch:3, Batch:239, Loss:0.132639, Acc:96.8750\n",
      "Train: Epoch:3, Batch:259, Loss:0.415500, Acc:84.3750\n",
      "Train: Epoch:3, Batch:279, Loss:0.082857, Acc:96.8750\n",
      "Train: Epoch:3, Batch:299, Loss:0.165395, Acc:90.6250\n",
      "Train: Epoch:3, Batch:319, Loss:0.089648, Acc:96.8750\n",
      "Train: Epoch:3, Batch:339, Loss:0.128046, Acc:96.8750\n",
      "Train: Epoch:3, Batch:359, Loss:0.307344, Acc:84.3750\n",
      "Train: Epoch:3, Batch:379, Loss:0.053873, Acc:96.8750\n",
      "Train: Epoch:3, Batch:399, Loss:0.189068, Acc:93.7500\n",
      "Train: Epoch:3, Batch:419, Loss:0.243901, Acc:93.7500\n",
      "Train: Epoch:3, Batch:439, Loss:0.167350, Acc:90.6250\n",
      "Train: Epoch:3, Batch:459, Loss:0.256726, Acc:90.6250\n",
      "Train: Epoch:3, Batch:479, Loss:0.178788, Acc:90.6250\n",
      "Train: Epoch:3, Batch:499, Loss:0.148657, Acc:90.6250\n",
      "Train: Epoch:3, Batch:519, Loss:0.153734, Acc:93.7500\n",
      "Train: Epoch:3, Batch:539, Loss:0.030852, Acc:100.0000\n",
      "Train: Epoch:3, Batch:559, Loss:0.162216, Acc:93.7500\n",
      "Train: Epoch:3, Batch:579, Loss:0.395628, Acc:84.3750\n",
      "Train: Epoch:3, Batch:599, Loss:0.145110, Acc:93.7500\n",
      "Train: Epoch:3, Batch:619, Loss:0.227138, Acc:84.3750\n",
      "Train: Epoch:3, Batch:639, Loss:0.116345, Acc:93.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:3, Batch:659, Loss:0.261186, Acc:84.3750\n",
      "Train: Epoch:3, Batch:679, Loss:0.288735, Acc:87.5000\n",
      "Train: Epoch:3, Batch:699, Loss:0.473454, Acc:84.3750\n",
      "Train: Epoch:3, Batch:719, Loss:0.095166, Acc:96.8750\n",
      "Train: Epoch:3, Batch:739, Loss:0.293026, Acc:87.5000\n",
      "Train_: Avg Training Loss: 0.197340, Avg Training Acc: 92.404167\n",
      "Val_: Total Validation Loss: 1.214170, Acc: 70.9125\n",
      "Test_: Total Testing Acc: 71.3125\n",
      "Time taken = 1975.4974 s\n",
      "\n",
      "Train: Epoch:4, Batch:19, Loss:0.039414, Acc:100.0000\n",
      "Train: Epoch:4, Batch:39, Loss:0.146688, Acc:96.8750\n",
      "Train: Epoch:4, Batch:59, Loss:0.366090, Acc:81.2500\n",
      "Train: Epoch:4, Batch:79, Loss:0.217482, Acc:90.6250\n",
      "Train: Epoch:4, Batch:99, Loss:0.080096, Acc:96.8750\n",
      "Train: Epoch:4, Batch:119, Loss:0.154731, Acc:90.6250\n",
      "Train: Epoch:4, Batch:139, Loss:0.178881, Acc:93.7500\n",
      "Train: Epoch:4, Batch:159, Loss:0.163252, Acc:90.6250\n",
      "Train: Epoch:4, Batch:179, Loss:0.190591, Acc:93.7500\n",
      "Train: Epoch:4, Batch:199, Loss:0.341482, Acc:84.3750\n",
      "Train: Epoch:4, Batch:219, Loss:0.221764, Acc:96.8750\n",
      "Train: Epoch:4, Batch:239, Loss:0.226501, Acc:90.6250\n",
      "Train: Epoch:4, Batch:259, Loss:0.184660, Acc:93.7500\n",
      "Train: Epoch:4, Batch:279, Loss:0.288483, Acc:93.7500\n",
      "Train: Epoch:4, Batch:299, Loss:0.185446, Acc:93.7500\n",
      "Train: Epoch:4, Batch:319, Loss:0.179302, Acc:93.7500\n",
      "Train: Epoch:4, Batch:339, Loss:0.168918, Acc:93.7500\n",
      "Train: Epoch:4, Batch:359, Loss:0.113605, Acc:93.7500\n",
      "Train: Epoch:4, Batch:379, Loss:0.245728, Acc:84.3750\n",
      "Train: Epoch:4, Batch:399, Loss:0.468577, Acc:84.3750\n",
      "Train: Epoch:4, Batch:419, Loss:0.202792, Acc:93.7500\n",
      "Train: Epoch:4, Batch:439, Loss:0.261036, Acc:93.7500\n",
      "Train: Epoch:4, Batch:459, Loss:0.152477, Acc:93.7500\n",
      "Train: Epoch:4, Batch:479, Loss:0.230626, Acc:93.7500\n",
      "Train: Epoch:4, Batch:499, Loss:0.118721, Acc:96.8750\n",
      "Train: Epoch:4, Batch:519, Loss:0.234729, Acc:90.6250\n",
      "Train: Epoch:4, Batch:539, Loss:0.128100, Acc:93.7500\n",
      "Train: Epoch:4, Batch:559, Loss:0.164440, Acc:96.8750\n",
      "Train: Epoch:4, Batch:579, Loss:0.216719, Acc:93.7500\n",
      "Train: Epoch:4, Batch:599, Loss:0.217673, Acc:93.7500\n",
      "Train: Epoch:4, Batch:619, Loss:0.403482, Acc:87.5000\n",
      "Train: Epoch:4, Batch:639, Loss:0.089141, Acc:100.0000\n",
      "Train: Epoch:4, Batch:659, Loss:0.211265, Acc:87.5000\n",
      "Train: Epoch:4, Batch:679, Loss:0.501231, Acc:81.2500\n",
      "Train: Epoch:4, Batch:699, Loss:0.385256, Acc:87.5000\n",
      "Train: Epoch:4, Batch:719, Loss:0.158640, Acc:90.6250\n",
      "Train: Epoch:4, Batch:739, Loss:0.124318, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.180636, Avg Training Acc: 93.066667\n",
      "Val_: Total Validation Loss: 1.223133, Acc: 70.8250\n",
      "Test_: Total Testing Acc: 71.7125\n",
      "Time taken = 2219.9377 s\n",
      "\n",
      "Train: Epoch:5, Batch:19, Loss:0.215793, Acc:90.6250\n",
      "Train: Epoch:5, Batch:39, Loss:0.134765, Acc:96.8750\n",
      "Train: Epoch:5, Batch:59, Loss:0.118959, Acc:93.7500\n",
      "Train: Epoch:5, Batch:79, Loss:0.057139, Acc:100.0000\n",
      "Train: Epoch:5, Batch:99, Loss:0.083337, Acc:96.8750\n",
      "Train: Epoch:5, Batch:119, Loss:0.234370, Acc:93.7500\n",
      "Train: Epoch:5, Batch:139, Loss:0.214703, Acc:90.6250\n",
      "Train: Epoch:5, Batch:159, Loss:0.072713, Acc:96.8750\n",
      "Train: Epoch:5, Batch:179, Loss:0.075519, Acc:96.8750\n",
      "Train: Epoch:5, Batch:199, Loss:0.180022, Acc:93.7500\n",
      "Train: Epoch:5, Batch:219, Loss:0.198460, Acc:90.6250\n",
      "Train: Epoch:5, Batch:239, Loss:0.089596, Acc:100.0000\n",
      "Train: Epoch:5, Batch:259, Loss:0.106626, Acc:96.8750\n",
      "Train: Epoch:5, Batch:279, Loss:0.104497, Acc:96.8750\n",
      "Train: Epoch:5, Batch:299, Loss:0.194266, Acc:93.7500\n",
      "Train: Epoch:5, Batch:319, Loss:0.519479, Acc:87.5000\n",
      "Train: Epoch:5, Batch:339, Loss:0.127611, Acc:96.8750\n",
      "Train: Epoch:5, Batch:359, Loss:0.113398, Acc:90.6250\n",
      "Train: Epoch:5, Batch:379, Loss:0.314225, Acc:90.6250\n",
      "Train: Epoch:5, Batch:399, Loss:0.110169, Acc:96.8750\n",
      "Train: Epoch:5, Batch:419, Loss:0.239965, Acc:93.7500\n",
      "Train: Epoch:5, Batch:439, Loss:0.297627, Acc:90.6250\n",
      "Train: Epoch:5, Batch:459, Loss:0.217712, Acc:90.6250\n",
      "Train: Epoch:5, Batch:479, Loss:0.210146, Acc:87.5000\n",
      "Train: Epoch:5, Batch:499, Loss:0.154315, Acc:93.7500\n",
      "Train: Epoch:5, Batch:519, Loss:0.312409, Acc:90.6250\n",
      "Train: Epoch:5, Batch:539, Loss:0.260485, Acc:87.5000\n",
      "Train: Epoch:5, Batch:559, Loss:0.298707, Acc:90.6250\n",
      "Train: Epoch:5, Batch:579, Loss:0.208292, Acc:90.6250\n",
      "Train: Epoch:5, Batch:599, Loss:0.165918, Acc:93.7500\n",
      "Train: Epoch:5, Batch:619, Loss:0.141318, Acc:93.7500\n",
      "Train: Epoch:5, Batch:639, Loss:0.157160, Acc:93.7500\n",
      "Train: Epoch:5, Batch:659, Loss:0.314609, Acc:84.3750\n",
      "Train: Epoch:5, Batch:679, Loss:0.435335, Acc:87.5000\n",
      "Train: Epoch:5, Batch:699, Loss:0.380274, Acc:87.5000\n",
      "Train: Epoch:5, Batch:719, Loss:0.485863, Acc:87.5000\n",
      "Train: Epoch:5, Batch:739, Loss:0.149129, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.194733, Avg Training Acc: 92.450000\n",
      "Val_: Total Validation Loss: 1.202814, Acc: 71.1750\n",
      "Test_: Total Testing Acc: 71.3250\n",
      "Time taken = 1968.4315 s\n",
      "\n",
      "Train: Epoch:6, Batch:19, Loss:0.217850, Acc:93.7500\n",
      "Train: Epoch:6, Batch:39, Loss:0.042852, Acc:100.0000\n",
      "Train: Epoch:6, Batch:59, Loss:0.243618, Acc:90.6250\n",
      "Train: Epoch:6, Batch:79, Loss:0.093084, Acc:96.8750\n",
      "Train: Epoch:6, Batch:99, Loss:0.251201, Acc:93.7500\n",
      "Train: Epoch:6, Batch:119, Loss:0.153643, Acc:93.7500\n",
      "Train: Epoch:6, Batch:139, Loss:0.113436, Acc:96.8750\n",
      "Train: Epoch:6, Batch:159, Loss:0.337802, Acc:87.5000\n",
      "Train: Epoch:6, Batch:179, Loss:0.123527, Acc:96.8750\n",
      "Train: Epoch:6, Batch:199, Loss:0.107342, Acc:93.7500\n",
      "Train: Epoch:6, Batch:219, Loss:0.307119, Acc:84.3750\n",
      "Train: Epoch:6, Batch:239, Loss:0.046644, Acc:100.0000\n",
      "Train: Epoch:6, Batch:259, Loss:0.049529, Acc:100.0000\n",
      "Train: Epoch:6, Batch:279, Loss:0.241203, Acc:90.6250\n",
      "Train: Epoch:6, Batch:299, Loss:0.120103, Acc:96.8750\n",
      "Train: Epoch:6, Batch:319, Loss:0.259997, Acc:93.7500\n",
      "Train: Epoch:6, Batch:339, Loss:0.177205, Acc:90.6250\n",
      "Train: Epoch:6, Batch:359, Loss:0.223296, Acc:87.5000\n",
      "Train: Epoch:6, Batch:379, Loss:0.258687, Acc:93.7500\n",
      "Train: Epoch:6, Batch:399, Loss:0.079113, Acc:96.8750\n",
      "Train: Epoch:6, Batch:419, Loss:0.205101, Acc:93.7500\n",
      "Train: Epoch:6, Batch:439, Loss:0.272979, Acc:87.5000\n",
      "Train: Epoch:6, Batch:459, Loss:0.128651, Acc:96.8750\n",
      "Train: Epoch:6, Batch:479, Loss:0.461729, Acc:93.7500\n",
      "Train: Epoch:6, Batch:499, Loss:0.525841, Acc:78.1250\n",
      "Train: Epoch:6, Batch:519, Loss:0.240108, Acc:96.8750\n",
      "Train: Epoch:6, Batch:539, Loss:0.157632, Acc:93.7500\n",
      "Train: Epoch:6, Batch:559, Loss:0.238445, Acc:90.6250\n",
      "Train: Epoch:6, Batch:579, Loss:0.145758, Acc:93.7500\n",
      "Train: Epoch:6, Batch:599, Loss:0.255247, Acc:81.2500\n",
      "Train: Epoch:6, Batch:619, Loss:0.193787, Acc:93.7500\n",
      "Train: Epoch:6, Batch:639, Loss:0.140817, Acc:93.7500\n",
      "Train: Epoch:6, Batch:659, Loss:0.217777, Acc:87.5000\n",
      "Train: Epoch:6, Batch:679, Loss:0.084245, Acc:96.8750\n",
      "Train: Epoch:6, Batch:699, Loss:0.224522, Acc:93.7500\n",
      "Train: Epoch:6, Batch:719, Loss:0.222305, Acc:90.6250\n",
      "Train: Epoch:6, Batch:739, Loss:0.130840, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.189813, Avg Training Acc: 92.833333\n",
      "Val_: Total Validation Loss: 1.199462, Acc: 71.3875\n",
      "Test_: Total Testing Acc: 71.1000\n",
      "Time taken = 1969.9662 s\n",
      "\n",
      "Train: Epoch:7, Batch:19, Loss:0.205403, Acc:93.7500\n",
      "Train: Epoch:7, Batch:39, Loss:0.112825, Acc:96.8750\n",
      "Train: Epoch:7, Batch:59, Loss:0.120699, Acc:93.7500\n",
      "Train: Epoch:7, Batch:79, Loss:0.133273, Acc:96.8750\n",
      "Train: Epoch:7, Batch:99, Loss:0.139555, Acc:93.7500\n",
      "Train: Epoch:7, Batch:119, Loss:0.100877, Acc:96.8750\n",
      "Train: Epoch:7, Batch:139, Loss:0.175986, Acc:93.7500\n",
      "Train: Epoch:7, Batch:159, Loss:0.114068, Acc:96.8750\n",
      "Train: Epoch:7, Batch:179, Loss:0.079197, Acc:96.8750\n",
      "Train: Epoch:7, Batch:199, Loss:0.309386, Acc:90.6250\n",
      "Train: Epoch:7, Batch:219, Loss:0.096037, Acc:96.8750\n",
      "Train: Epoch:7, Batch:239, Loss:0.057647, Acc:100.0000\n",
      "Train: Epoch:7, Batch:259, Loss:0.112776, Acc:96.8750\n",
      "Train: Epoch:7, Batch:279, Loss:0.086489, Acc:96.8750\n",
      "Train: Epoch:7, Batch:299, Loss:0.197782, Acc:93.7500\n",
      "Train: Epoch:7, Batch:319, Loss:0.254164, Acc:90.6250\n",
      "Train: Epoch:7, Batch:339, Loss:0.213495, Acc:87.5000\n",
      "Train: Epoch:7, Batch:359, Loss:0.194619, Acc:93.7500\n",
      "Train: Epoch:7, Batch:379, Loss:0.213819, Acc:87.5000\n",
      "Train: Epoch:7, Batch:399, Loss:0.048550, Acc:96.8750\n",
      "Train: Epoch:7, Batch:419, Loss:0.130437, Acc:93.7500\n",
      "Train: Epoch:7, Batch:439, Loss:0.119112, Acc:96.8750\n",
      "Train: Epoch:7, Batch:459, Loss:0.054099, Acc:96.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:7, Batch:479, Loss:0.338328, Acc:90.6250\n",
      "Train: Epoch:7, Batch:499, Loss:0.172356, Acc:87.5000\n",
      "Train: Epoch:7, Batch:519, Loss:0.105574, Acc:96.8750\n",
      "Train: Epoch:7, Batch:539, Loss:0.414000, Acc:81.2500\n",
      "Train: Epoch:7, Batch:559, Loss:0.124856, Acc:93.7500\n",
      "Train: Epoch:7, Batch:579, Loss:0.213294, Acc:90.6250\n",
      "Train: Epoch:7, Batch:599, Loss:0.106667, Acc:96.8750\n",
      "Train: Epoch:7, Batch:619, Loss:0.208634, Acc:90.6250\n",
      "Train: Epoch:7, Batch:639, Loss:0.239683, Acc:84.3750\n",
      "Train: Epoch:7, Batch:659, Loss:0.186554, Acc:87.5000\n",
      "Train: Epoch:7, Batch:679, Loss:0.089331, Acc:96.8750\n",
      "Train: Epoch:7, Batch:699, Loss:0.179390, Acc:93.7500\n",
      "Train: Epoch:7, Batch:719, Loss:0.079456, Acc:96.8750\n",
      "Train: Epoch:7, Batch:739, Loss:0.053988, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.163890, Avg Training Acc: 93.758333\n",
      "Val_: Total Validation Loss: 1.279206, Acc: 70.6125\n",
      "Test_: Total Testing Acc: 71.3750\n",
      "Time taken = 2013.3952 s\n",
      "\n",
      "Train: Epoch:8, Batch:19, Loss:0.180141, Acc:93.7500\n",
      "Train: Epoch:8, Batch:39, Loss:0.107472, Acc:93.7500\n",
      "Train: Epoch:8, Batch:59, Loss:0.341843, Acc:90.6250\n",
      "Train: Epoch:8, Batch:79, Loss:0.259655, Acc:87.5000\n",
      "Train: Epoch:8, Batch:99, Loss:0.172658, Acc:90.6250\n",
      "Train: Epoch:8, Batch:119, Loss:0.153010, Acc:90.6250\n",
      "Train: Epoch:8, Batch:139, Loss:0.105515, Acc:93.7500\n",
      "Train: Epoch:8, Batch:159, Loss:0.379062, Acc:84.3750\n",
      "Train: Epoch:8, Batch:179, Loss:0.233823, Acc:90.6250\n",
      "Train: Epoch:8, Batch:199, Loss:0.185053, Acc:93.7500\n",
      "Train: Epoch:8, Batch:219, Loss:0.201408, Acc:90.6250\n",
      "Train: Epoch:8, Batch:239, Loss:0.219885, Acc:93.7500\n",
      "Train: Epoch:8, Batch:259, Loss:0.153270, Acc:93.7500\n",
      "Train: Epoch:8, Batch:279, Loss:0.251573, Acc:93.7500\n",
      "Train: Epoch:8, Batch:299, Loss:0.241494, Acc:96.8750\n",
      "Train: Epoch:8, Batch:319, Loss:0.192997, Acc:93.7500\n",
      "Train: Epoch:8, Batch:339, Loss:0.231627, Acc:93.7500\n",
      "Train: Epoch:8, Batch:359, Loss:0.100592, Acc:96.8750\n",
      "Train: Epoch:8, Batch:379, Loss:0.208095, Acc:93.7500\n",
      "Train: Epoch:8, Batch:399, Loss:0.159214, Acc:96.8750\n",
      "Train: Epoch:8, Batch:419, Loss:0.133902, Acc:90.6250\n",
      "Train: Epoch:8, Batch:439, Loss:0.046883, Acc:96.8750\n",
      "Train: Epoch:8, Batch:459, Loss:0.056624, Acc:100.0000\n",
      "Train: Epoch:8, Batch:479, Loss:0.106904, Acc:96.8750\n",
      "Train: Epoch:8, Batch:499, Loss:0.063340, Acc:100.0000\n",
      "Train: Epoch:8, Batch:519, Loss:0.143689, Acc:93.7500\n",
      "Train: Epoch:8, Batch:539, Loss:0.195035, Acc:90.6250\n",
      "Train: Epoch:8, Batch:559, Loss:0.304334, Acc:93.7500\n",
      "Train: Epoch:8, Batch:579, Loss:0.124367, Acc:96.8750\n",
      "Train: Epoch:8, Batch:599, Loss:0.147213, Acc:90.6250\n",
      "Train: Epoch:8, Batch:619, Loss:0.175988, Acc:93.7500\n",
      "Train: Epoch:8, Batch:639, Loss:0.169816, Acc:93.7500\n",
      "Train: Epoch:8, Batch:659, Loss:0.228775, Acc:90.6250\n",
      "Train: Epoch:8, Batch:679, Loss:0.179064, Acc:87.5000\n",
      "Train: Epoch:8, Batch:699, Loss:0.405490, Acc:90.6250\n",
      "Train: Epoch:8, Batch:719, Loss:0.151484, Acc:93.7500\n",
      "Train: Epoch:8, Batch:739, Loss:0.061952, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.193261, Avg Training Acc: 92.625000\n",
      "Val_: Total Validation Loss: 1.182628, Acc: 71.2625\n",
      "Test_: Total Testing Acc: 71.5375\n",
      "Time taken = 1967.6535 s\n",
      "\n",
      "Train: Epoch:9, Batch:19, Loss:0.192175, Acc:96.8750\n",
      "Train: Epoch:9, Batch:39, Loss:0.171874, Acc:93.7500\n",
      "Train: Epoch:9, Batch:59, Loss:0.321021, Acc:81.2500\n",
      "Train: Epoch:9, Batch:79, Loss:0.224523, Acc:87.5000\n",
      "Train: Epoch:9, Batch:99, Loss:0.304026, Acc:90.6250\n",
      "Train: Epoch:9, Batch:119, Loss:0.130487, Acc:96.8750\n",
      "Train: Epoch:9, Batch:139, Loss:0.244440, Acc:90.6250\n",
      "Train: Epoch:9, Batch:159, Loss:0.207833, Acc:93.7500\n",
      "Train: Epoch:9, Batch:179, Loss:0.185121, Acc:96.8750\n",
      "Train: Epoch:9, Batch:199, Loss:0.133769, Acc:96.8750\n",
      "Train: Epoch:9, Batch:219, Loss:0.141451, Acc:90.6250\n",
      "Train: Epoch:9, Batch:239, Loss:0.140710, Acc:93.7500\n",
      "Train: Epoch:9, Batch:259, Loss:0.186398, Acc:96.8750\n",
      "Train: Epoch:9, Batch:279, Loss:0.148538, Acc:90.6250\n",
      "Train: Epoch:9, Batch:299, Loss:0.187443, Acc:90.6250\n",
      "Train: Epoch:9, Batch:319, Loss:0.028076, Acc:100.0000\n",
      "Train: Epoch:9, Batch:339, Loss:0.061213, Acc:96.8750\n",
      "Train: Epoch:9, Batch:359, Loss:0.112331, Acc:96.8750\n",
      "Train: Epoch:9, Batch:379, Loss:0.345752, Acc:90.6250\n",
      "Train: Epoch:9, Batch:399, Loss:0.157215, Acc:90.6250\n",
      "Train: Epoch:9, Batch:419, Loss:0.056007, Acc:96.8750\n",
      "Train: Epoch:9, Batch:439, Loss:0.202655, Acc:90.6250\n",
      "Train: Epoch:9, Batch:459, Loss:0.072532, Acc:100.0000\n",
      "Train: Epoch:9, Batch:479, Loss:0.093623, Acc:100.0000\n",
      "Train: Epoch:9, Batch:499, Loss:0.354335, Acc:84.3750\n",
      "Train: Epoch:9, Batch:519, Loss:0.292116, Acc:90.6250\n",
      "Train: Epoch:9, Batch:539, Loss:0.213966, Acc:93.7500\n",
      "Train: Epoch:9, Batch:559, Loss:0.620715, Acc:81.2500\n",
      "Train: Epoch:9, Batch:579, Loss:0.157969, Acc:87.5000\n",
      "Train: Epoch:9, Batch:599, Loss:0.276220, Acc:90.6250\n",
      "Train: Epoch:9, Batch:619, Loss:0.123619, Acc:90.6250\n",
      "Train: Epoch:9, Batch:639, Loss:0.277537, Acc:87.5000\n",
      "Train: Epoch:9, Batch:659, Loss:0.070061, Acc:96.8750\n",
      "Train: Epoch:9, Batch:679, Loss:0.086072, Acc:96.8750\n",
      "Train: Epoch:9, Batch:699, Loss:0.181927, Acc:93.7500\n",
      "Train: Epoch:9, Batch:719, Loss:0.283085, Acc:81.2500\n",
      "Train: Epoch:9, Batch:739, Loss:0.291997, Acc:81.2500\n",
      "Train_: Avg Training Loss: 0.160770, Avg Training Acc: 93.879167\n",
      "Val_: Total Validation Loss: 1.264306, Acc: 71.0250\n",
      "Test_: Total Testing Acc: 71.0625\n",
      "Time taken = 1955.1614 s\n",
      "\n",
      "Train: Epoch:10, Batch:19, Loss:0.147736, Acc:96.8750\n",
      "Train: Epoch:10, Batch:39, Loss:0.073947, Acc:96.8750\n",
      "Train: Epoch:10, Batch:59, Loss:0.114963, Acc:93.7500\n",
      "Train: Epoch:10, Batch:79, Loss:0.303718, Acc:90.6250\n",
      "Train: Epoch:10, Batch:99, Loss:0.242478, Acc:90.6250\n",
      "Train: Epoch:10, Batch:119, Loss:0.135479, Acc:93.7500\n",
      "Train: Epoch:10, Batch:139, Loss:0.126951, Acc:96.8750\n",
      "Train: Epoch:10, Batch:159, Loss:0.053957, Acc:100.0000\n",
      "Train: Epoch:10, Batch:179, Loss:0.184249, Acc:90.6250\n",
      "Train: Epoch:10, Batch:199, Loss:0.129345, Acc:96.8750\n",
      "Train: Epoch:10, Batch:219, Loss:0.243378, Acc:93.7500\n",
      "Train: Epoch:10, Batch:239, Loss:0.157096, Acc:90.6250\n",
      "Train: Epoch:10, Batch:259, Loss:0.170240, Acc:96.8750\n",
      "Train: Epoch:10, Batch:279, Loss:0.113890, Acc:96.8750\n",
      "Train: Epoch:10, Batch:299, Loss:0.140024, Acc:90.6250\n",
      "Train: Epoch:10, Batch:319, Loss:0.182651, Acc:87.5000\n",
      "Train: Epoch:10, Batch:339, Loss:0.092345, Acc:96.8750\n",
      "Train: Epoch:10, Batch:359, Loss:0.256014, Acc:90.6250\n",
      "Train: Epoch:10, Batch:379, Loss:0.192453, Acc:93.7500\n",
      "Train: Epoch:10, Batch:399, Loss:0.087396, Acc:96.8750\n",
      "Train: Epoch:10, Batch:419, Loss:0.230240, Acc:93.7500\n",
      "Train: Epoch:10, Batch:439, Loss:0.050486, Acc:100.0000\n",
      "Train: Epoch:10, Batch:459, Loss:0.275057, Acc:93.7500\n",
      "Train: Epoch:10, Batch:479, Loss:0.331052, Acc:87.5000\n",
      "Train: Epoch:10, Batch:499, Loss:0.281355, Acc:84.3750\n",
      "Train: Epoch:10, Batch:519, Loss:0.276748, Acc:90.6250\n",
      "Train: Epoch:10, Batch:539, Loss:0.340194, Acc:90.6250\n",
      "Train: Epoch:10, Batch:559, Loss:0.149459, Acc:93.7500\n",
      "Train: Epoch:10, Batch:579, Loss:0.145599, Acc:96.8750\n",
      "Train: Epoch:10, Batch:599, Loss:0.198950, Acc:93.7500\n",
      "Train: Epoch:10, Batch:619, Loss:0.410961, Acc:87.5000\n",
      "Train: Epoch:10, Batch:639, Loss:0.085220, Acc:96.8750\n",
      "Train: Epoch:10, Batch:659, Loss:0.149902, Acc:93.7500\n",
      "Train: Epoch:10, Batch:679, Loss:0.153802, Acc:93.7500\n",
      "Train: Epoch:10, Batch:699, Loss:0.179444, Acc:93.7500\n",
      "Train: Epoch:10, Batch:719, Loss:0.356086, Acc:90.6250\n",
      "Train: Epoch:10, Batch:739, Loss:0.237139, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.181380, Avg Training Acc: 93.070833\n",
      "Val_: Total Validation Loss: 1.258990, Acc: 71.6125\n",
      "Test_: Total Testing Acc: 71.6000\n",
      "Time taken = 1997.8811 s\n",
      "\n",
      "Train: Epoch:11, Batch:19, Loss:0.115590, Acc:93.7500\n",
      "Train: Epoch:11, Batch:39, Loss:0.183245, Acc:96.8750\n",
      "Train: Epoch:11, Batch:59, Loss:0.099979, Acc:96.8750\n",
      "Train: Epoch:11, Batch:79, Loss:0.169815, Acc:96.8750\n",
      "Train: Epoch:11, Batch:99, Loss:0.124594, Acc:96.8750\n",
      "Train: Epoch:11, Batch:119, Loss:0.127274, Acc:93.7500\n",
      "Train: Epoch:11, Batch:139, Loss:0.063491, Acc:100.0000\n",
      "Train: Epoch:11, Batch:159, Loss:0.036107, Acc:100.0000\n",
      "Train: Epoch:11, Batch:179, Loss:0.109863, Acc:96.8750\n",
      "Train: Epoch:11, Batch:199, Loss:0.140680, Acc:96.8750\n",
      "Train: Epoch:11, Batch:219, Loss:0.367475, Acc:78.1250\n",
      "Train: Epoch:11, Batch:239, Loss:0.033791, Acc:100.0000\n",
      "Train: Epoch:11, Batch:259, Loss:0.095902, Acc:96.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:11, Batch:279, Loss:0.091661, Acc:100.0000\n",
      "Train: Epoch:11, Batch:299, Loss:0.419169, Acc:87.5000\n",
      "Train: Epoch:11, Batch:319, Loss:0.156915, Acc:96.8750\n",
      "Train: Epoch:11, Batch:339, Loss:0.074185, Acc:100.0000\n",
      "Train: Epoch:11, Batch:359, Loss:0.263249, Acc:87.5000\n",
      "Train: Epoch:11, Batch:379, Loss:0.029427, Acc:100.0000\n",
      "Train: Epoch:11, Batch:399, Loss:0.133304, Acc:93.7500\n",
      "Train: Epoch:11, Batch:419, Loss:0.347372, Acc:84.3750\n",
      "Train: Epoch:11, Batch:439, Loss:0.108162, Acc:96.8750\n",
      "Train: Epoch:11, Batch:459, Loss:0.296727, Acc:93.7500\n",
      "Train: Epoch:11, Batch:479, Loss:0.198997, Acc:87.5000\n",
      "Train: Epoch:11, Batch:499, Loss:0.245256, Acc:87.5000\n",
      "Train: Epoch:11, Batch:519, Loss:0.229080, Acc:93.7500\n",
      "Train: Epoch:11, Batch:539, Loss:0.193307, Acc:87.5000\n",
      "Train: Epoch:11, Batch:559, Loss:0.153056, Acc:93.7500\n",
      "Train: Epoch:11, Batch:579, Loss:0.223167, Acc:93.7500\n",
      "Train: Epoch:11, Batch:599, Loss:0.127017, Acc:96.8750\n",
      "Train: Epoch:11, Batch:619, Loss:0.198336, Acc:90.6250\n",
      "Train: Epoch:11, Batch:639, Loss:0.244110, Acc:84.3750\n",
      "Train: Epoch:11, Batch:659, Loss:0.185393, Acc:87.5000\n",
      "Train: Epoch:11, Batch:679, Loss:0.128733, Acc:96.8750\n",
      "Train: Epoch:11, Batch:699, Loss:0.376096, Acc:84.3750\n",
      "Train: Epoch:11, Batch:719, Loss:0.137830, Acc:96.8750\n",
      "Train: Epoch:11, Batch:739, Loss:0.181427, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.170792, Avg Training Acc: 93.545833\n",
      "Val_: Total Validation Loss: 1.288417, Acc: 71.7375\n",
      "Test_: Total Testing Acc: 71.0000\n",
      "Time taken = 1969.4308 s\n",
      "\n",
      "Train: Epoch:12, Batch:19, Loss:0.246210, Acc:87.5000\n",
      "Train: Epoch:12, Batch:39, Loss:0.158014, Acc:93.7500\n",
      "Train: Epoch:12, Batch:59, Loss:0.155463, Acc:93.7500\n",
      "Train: Epoch:12, Batch:79, Loss:0.052663, Acc:100.0000\n",
      "Train: Epoch:12, Batch:99, Loss:0.109898, Acc:96.8750\n",
      "Train: Epoch:12, Batch:119, Loss:0.294246, Acc:84.3750\n",
      "Train: Epoch:12, Batch:139, Loss:0.155549, Acc:93.7500\n",
      "Train: Epoch:12, Batch:159, Loss:0.149509, Acc:90.6250\n",
      "Train: Epoch:12, Batch:179, Loss:0.152162, Acc:87.5000\n",
      "Train: Epoch:12, Batch:199, Loss:0.030264, Acc:100.0000\n",
      "Train: Epoch:12, Batch:219, Loss:0.074892, Acc:100.0000\n",
      "Train: Epoch:12, Batch:239, Loss:0.155169, Acc:93.7500\n",
      "Train: Epoch:12, Batch:259, Loss:0.211038, Acc:87.5000\n",
      "Train: Epoch:12, Batch:279, Loss:0.102187, Acc:96.8750\n",
      "Train: Epoch:12, Batch:299, Loss:0.300120, Acc:90.6250\n",
      "Train: Epoch:12, Batch:319, Loss:0.112754, Acc:96.8750\n",
      "Train: Epoch:12, Batch:339, Loss:0.115833, Acc:93.7500\n",
      "Train: Epoch:12, Batch:359, Loss:0.264529, Acc:90.6250\n",
      "Train: Epoch:12, Batch:379, Loss:0.163093, Acc:93.7500\n",
      "Train: Epoch:12, Batch:399, Loss:0.053890, Acc:96.8750\n",
      "Train: Epoch:12, Batch:419, Loss:0.088327, Acc:96.8750\n",
      "Train: Epoch:12, Batch:439, Loss:0.066469, Acc:100.0000\n",
      "Train: Epoch:12, Batch:459, Loss:0.145125, Acc:93.7500\n",
      "Train: Epoch:12, Batch:479, Loss:0.297802, Acc:96.8750\n",
      "Train: Epoch:12, Batch:499, Loss:0.249479, Acc:87.5000\n",
      "Train: Epoch:12, Batch:519, Loss:0.265080, Acc:87.5000\n",
      "Train: Epoch:12, Batch:539, Loss:0.138672, Acc:93.7500\n",
      "Train: Epoch:12, Batch:559, Loss:0.116850, Acc:93.7500\n",
      "Train: Epoch:12, Batch:579, Loss:0.380502, Acc:90.6250\n",
      "Train: Epoch:12, Batch:599, Loss:0.073060, Acc:96.8750\n",
      "Train: Epoch:12, Batch:619, Loss:0.086822, Acc:93.7500\n",
      "Train: Epoch:12, Batch:639, Loss:0.158431, Acc:93.7500\n",
      "Train: Epoch:12, Batch:659, Loss:0.175167, Acc:93.7500\n",
      "Train: Epoch:12, Batch:679, Loss:0.029074, Acc:100.0000\n",
      "Train: Epoch:12, Batch:699, Loss:0.140349, Acc:93.7500\n",
      "Train: Epoch:12, Batch:719, Loss:0.103304, Acc:96.8750\n",
      "Train: Epoch:12, Batch:739, Loss:0.143252, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.163048, Avg Training Acc: 93.670833\n",
      "Val_: Total Validation Loss: 1.301296, Acc: 71.6500\n",
      "Test_: Total Testing Acc: 71.7500\n",
      "Time taken = 1961.9850 s\n",
      "\n",
      "Train: Epoch:13, Batch:19, Loss:0.148018, Acc:90.6250\n",
      "Train: Epoch:13, Batch:39, Loss:0.119544, Acc:93.7500\n",
      "Train: Epoch:13, Batch:59, Loss:0.157022, Acc:93.7500\n",
      "Train: Epoch:13, Batch:79, Loss:0.157284, Acc:96.8750\n",
      "Train: Epoch:13, Batch:99, Loss:0.103928, Acc:96.8750\n",
      "Train: Epoch:13, Batch:119, Loss:0.092052, Acc:96.8750\n",
      "Train: Epoch:13, Batch:139, Loss:0.094376, Acc:93.7500\n",
      "Train: Epoch:13, Batch:159, Loss:0.245291, Acc:90.6250\n",
      "Train: Epoch:13, Batch:179, Loss:0.408379, Acc:90.6250\n",
      "Train: Epoch:13, Batch:199, Loss:0.116095, Acc:93.7500\n",
      "Train: Epoch:13, Batch:219, Loss:0.369822, Acc:90.6250\n",
      "Train: Epoch:13, Batch:239, Loss:0.173682, Acc:96.8750\n",
      "Train: Epoch:13, Batch:259, Loss:0.137254, Acc:96.8750\n",
      "Train: Epoch:13, Batch:279, Loss:0.228966, Acc:84.3750\n",
      "Train: Epoch:13, Batch:299, Loss:0.075449, Acc:96.8750\n",
      "Train: Epoch:13, Batch:319, Loss:0.194518, Acc:87.5000\n",
      "Train: Epoch:13, Batch:339, Loss:0.258788, Acc:90.6250\n",
      "Train: Epoch:13, Batch:359, Loss:0.142679, Acc:93.7500\n",
      "Train: Epoch:13, Batch:379, Loss:0.167737, Acc:90.6250\n",
      "Train: Epoch:13, Batch:399, Loss:0.151828, Acc:93.7500\n",
      "Train: Epoch:13, Batch:419, Loss:0.247528, Acc:87.5000\n",
      "Train: Epoch:13, Batch:439, Loss:0.183987, Acc:90.6250\n",
      "Train: Epoch:13, Batch:459, Loss:0.272337, Acc:84.3750\n",
      "Train: Epoch:13, Batch:479, Loss:0.137218, Acc:96.8750\n",
      "Train: Epoch:13, Batch:499, Loss:0.184712, Acc:87.5000\n",
      "Train: Epoch:13, Batch:519, Loss:0.165133, Acc:93.7500\n",
      "Train: Epoch:13, Batch:539, Loss:0.104640, Acc:93.7500\n",
      "Train: Epoch:13, Batch:559, Loss:0.163810, Acc:93.7500\n",
      "Train: Epoch:13, Batch:579, Loss:0.070451, Acc:100.0000\n",
      "Train: Epoch:13, Batch:599, Loss:0.254994, Acc:90.6250\n",
      "Train: Epoch:13, Batch:619, Loss:0.206737, Acc:93.7500\n",
      "Train: Epoch:13, Batch:639, Loss:0.143212, Acc:96.8750\n",
      "Train: Epoch:13, Batch:659, Loss:0.107404, Acc:93.7500\n",
      "Train: Epoch:13, Batch:679, Loss:0.143154, Acc:90.6250\n",
      "Train: Epoch:13, Batch:699, Loss:0.068222, Acc:96.8750\n",
      "Train: Epoch:13, Batch:719, Loss:0.097810, Acc:93.7500\n",
      "Train: Epoch:13, Batch:739, Loss:0.125553, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.164116, Avg Training Acc: 93.695833\n",
      "Val_: Total Validation Loss: 1.282033, Acc: 71.6125\n",
      "Test_: Total Testing Acc: 71.7000\n",
      "Time taken = 1960.6146 s\n",
      "\n",
      "Train: Epoch:14, Batch:19, Loss:0.172869, Acc:93.7500\n",
      "Train: Epoch:14, Batch:39, Loss:0.182782, Acc:93.7500\n",
      "Train: Epoch:14, Batch:59, Loss:0.075754, Acc:100.0000\n",
      "Train: Epoch:14, Batch:79, Loss:0.117701, Acc:90.6250\n",
      "Train: Epoch:14, Batch:99, Loss:0.126984, Acc:96.8750\n",
      "Train: Epoch:14, Batch:119, Loss:0.315388, Acc:84.3750\n",
      "Train: Epoch:14, Batch:139, Loss:0.037828, Acc:100.0000\n",
      "Train: Epoch:14, Batch:159, Loss:0.207903, Acc:93.7500\n",
      "Train: Epoch:14, Batch:179, Loss:0.120506, Acc:96.8750\n",
      "Train: Epoch:14, Batch:199, Loss:0.084725, Acc:96.8750\n",
      "Train: Epoch:14, Batch:219, Loss:0.179839, Acc:90.6250\n",
      "Train: Epoch:14, Batch:239, Loss:0.247701, Acc:81.2500\n",
      "Train: Epoch:14, Batch:259, Loss:0.247676, Acc:87.5000\n",
      "Train: Epoch:14, Batch:279, Loss:0.133877, Acc:93.7500\n",
      "Train: Epoch:14, Batch:299, Loss:0.260653, Acc:90.6250\n",
      "Train: Epoch:14, Batch:319, Loss:0.060457, Acc:96.8750\n",
      "Train: Epoch:14, Batch:339, Loss:0.221933, Acc:90.6250\n",
      "Train: Epoch:14, Batch:359, Loss:0.219533, Acc:90.6250\n",
      "Train: Epoch:14, Batch:379, Loss:0.130458, Acc:96.8750\n",
      "Train: Epoch:14, Batch:399, Loss:0.160574, Acc:90.6250\n",
      "Train: Epoch:14, Batch:419, Loss:0.183995, Acc:87.5000\n",
      "Train: Epoch:14, Batch:439, Loss:0.228500, Acc:90.6250\n",
      "Train: Epoch:14, Batch:459, Loss:0.322222, Acc:87.5000\n",
      "Train: Epoch:14, Batch:479, Loss:0.139868, Acc:93.7500\n",
      "Train: Epoch:14, Batch:499, Loss:0.111524, Acc:93.7500\n",
      "Train: Epoch:14, Batch:519, Loss:0.128918, Acc:93.7500\n",
      "Train: Epoch:14, Batch:539, Loss:0.177491, Acc:93.7500\n",
      "Train: Epoch:14, Batch:559, Loss:0.288190, Acc:87.5000\n",
      "Train: Epoch:14, Batch:579, Loss:0.179232, Acc:90.6250\n",
      "Train: Epoch:14, Batch:599, Loss:0.121880, Acc:93.7500\n",
      "Train: Epoch:14, Batch:619, Loss:0.143395, Acc:90.6250\n",
      "Train: Epoch:14, Batch:639, Loss:0.271278, Acc:93.7500\n",
      "Train: Epoch:14, Batch:659, Loss:0.350489, Acc:87.5000\n",
      "Train: Epoch:14, Batch:679, Loss:0.052212, Acc:100.0000\n",
      "Train: Epoch:14, Batch:699, Loss:0.088730, Acc:96.8750\n",
      "Train: Epoch:14, Batch:719, Loss:0.110152, Acc:96.8750\n",
      "Train: Epoch:14, Batch:739, Loss:0.103527, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.161179, Avg Training Acc: 93.858333\n",
      "Val_: Total Validation Loss: 1.306540, Acc: 71.0625\n",
      "Test_: Total Testing Acc: 71.7875\n",
      "Time taken = 2053.1740 s\n",
      "\n",
      "Train: Epoch:15, Batch:19, Loss:0.109213, Acc:93.7500\n",
      "Train: Epoch:15, Batch:39, Loss:0.141607, Acc:93.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:15, Batch:59, Loss:0.168957, Acc:90.6250\n",
      "Train: Epoch:15, Batch:79, Loss:0.250407, Acc:90.6250\n",
      "Train: Epoch:15, Batch:99, Loss:0.174407, Acc:93.7500\n",
      "Train: Epoch:15, Batch:119, Loss:0.108108, Acc:96.8750\n",
      "Train: Epoch:15, Batch:139, Loss:0.160835, Acc:93.7500\n",
      "Train: Epoch:15, Batch:159, Loss:0.040671, Acc:100.0000\n",
      "Train: Epoch:15, Batch:179, Loss:0.078708, Acc:100.0000\n",
      "Train: Epoch:15, Batch:199, Loss:0.067304, Acc:100.0000\n",
      "Train: Epoch:15, Batch:219, Loss:0.266765, Acc:87.5000\n",
      "Train: Epoch:15, Batch:239, Loss:0.113065, Acc:96.8750\n",
      "Train: Epoch:15, Batch:259, Loss:0.241152, Acc:90.6250\n",
      "Train: Epoch:15, Batch:279, Loss:0.064644, Acc:96.8750\n",
      "Train: Epoch:15, Batch:299, Loss:0.174059, Acc:90.6250\n",
      "Train: Epoch:15, Batch:319, Loss:0.207274, Acc:90.6250\n",
      "Train: Epoch:15, Batch:339, Loss:0.099867, Acc:96.8750\n",
      "Train: Epoch:15, Batch:359, Loss:0.030084, Acc:100.0000\n",
      "Train: Epoch:15, Batch:379, Loss:0.067621, Acc:96.8750\n",
      "Train: Epoch:15, Batch:399, Loss:0.121850, Acc:93.7500\n",
      "Train: Epoch:15, Batch:419, Loss:0.488575, Acc:93.7500\n",
      "Train: Epoch:15, Batch:439, Loss:0.467885, Acc:87.5000\n",
      "Train: Epoch:15, Batch:459, Loss:0.224716, Acc:96.8750\n",
      "Train: Epoch:15, Batch:479, Loss:0.088888, Acc:100.0000\n",
      "Train: Epoch:15, Batch:499, Loss:0.229727, Acc:90.6250\n",
      "Train: Epoch:15, Batch:519, Loss:0.017395, Acc:100.0000\n",
      "Train: Epoch:15, Batch:539, Loss:0.293218, Acc:87.5000\n",
      "Train: Epoch:15, Batch:559, Loss:0.353690, Acc:81.2500\n",
      "Train: Epoch:15, Batch:579, Loss:0.152161, Acc:93.7500\n",
      "Train: Epoch:15, Batch:599, Loss:0.232928, Acc:90.6250\n",
      "Train: Epoch:15, Batch:619, Loss:0.119582, Acc:93.7500\n",
      "Train: Epoch:15, Batch:639, Loss:0.106283, Acc:96.8750\n",
      "Train: Epoch:15, Batch:659, Loss:0.122347, Acc:93.7500\n",
      "Train: Epoch:15, Batch:679, Loss:0.111433, Acc:96.8750\n",
      "Train: Epoch:15, Batch:699, Loss:0.143960, Acc:93.7500\n",
      "Train: Epoch:15, Batch:719, Loss:0.077740, Acc:96.8750\n",
      "Train: Epoch:15, Batch:739, Loss:0.113864, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.159517, Avg Training Acc: 93.979167\n",
      "Val_: Total Validation Loss: 1.327205, Acc: 71.4125\n",
      "Test_: Total Testing Acc: 71.5500\n",
      "Time taken = 1977.9888 s\n",
      "\n",
      "Train: Epoch:16, Batch:19, Loss:0.086984, Acc:96.8750\n",
      "Train: Epoch:16, Batch:39, Loss:0.042561, Acc:100.0000\n",
      "Train: Epoch:16, Batch:59, Loss:0.258939, Acc:87.5000\n",
      "Train: Epoch:16, Batch:79, Loss:0.151429, Acc:96.8750\n",
      "Train: Epoch:16, Batch:99, Loss:0.037369, Acc:100.0000\n",
      "Train: Epoch:16, Batch:119, Loss:0.152000, Acc:96.8750\n",
      "Train: Epoch:16, Batch:139, Loss:0.320230, Acc:90.6250\n",
      "Train: Epoch:16, Batch:159, Loss:0.097330, Acc:96.8750\n",
      "Train: Epoch:16, Batch:179, Loss:0.161754, Acc:96.8750\n",
      "Train: Epoch:16, Batch:199, Loss:0.185029, Acc:87.5000\n",
      "Train: Epoch:16, Batch:219, Loss:0.085136, Acc:96.8750\n",
      "Train: Epoch:16, Batch:239, Loss:0.050405, Acc:100.0000\n",
      "Train: Epoch:16, Batch:259, Loss:0.092926, Acc:96.8750\n",
      "Train: Epoch:16, Batch:279, Loss:0.038258, Acc:100.0000\n",
      "Train: Epoch:16, Batch:299, Loss:0.306051, Acc:90.6250\n",
      "Train: Epoch:16, Batch:319, Loss:0.623026, Acc:84.3750\n",
      "Train: Epoch:16, Batch:339, Loss:0.228307, Acc:84.3750\n",
      "Train: Epoch:16, Batch:359, Loss:0.289371, Acc:90.6250\n",
      "Train: Epoch:16, Batch:379, Loss:0.349818, Acc:90.6250\n",
      "Train: Epoch:16, Batch:399, Loss:0.162762, Acc:90.6250\n",
      "Train: Epoch:16, Batch:419, Loss:0.303723, Acc:84.3750\n",
      "Train: Epoch:16, Batch:439, Loss:0.266401, Acc:87.5000\n",
      "Train: Epoch:16, Batch:459, Loss:0.090142, Acc:100.0000\n",
      "Train: Epoch:16, Batch:479, Loss:0.042704, Acc:100.0000\n",
      "Train: Epoch:16, Batch:499, Loss:0.143887, Acc:93.7500\n",
      "Train: Epoch:16, Batch:519, Loss:0.187245, Acc:90.6250\n",
      "Train: Epoch:16, Batch:539, Loss:0.209165, Acc:96.8750\n",
      "Train: Epoch:16, Batch:559, Loss:0.169734, Acc:90.6250\n",
      "Train: Epoch:16, Batch:579, Loss:0.211434, Acc:93.7500\n",
      "Train: Epoch:16, Batch:599, Loss:0.226298, Acc:90.6250\n",
      "Train: Epoch:16, Batch:619, Loss:0.039669, Acc:100.0000\n",
      "Train: Epoch:16, Batch:639, Loss:0.119374, Acc:90.6250\n",
      "Train: Epoch:16, Batch:659, Loss:0.095548, Acc:100.0000\n",
      "Train: Epoch:16, Batch:679, Loss:0.280534, Acc:87.5000\n",
      "Train: Epoch:16, Batch:699, Loss:0.080684, Acc:96.8750\n",
      "Train: Epoch:16, Batch:719, Loss:0.067516, Acc:96.8750\n",
      "Train: Epoch:16, Batch:739, Loss:0.147775, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.162027, Avg Training Acc: 93.900000\n",
      "Val_: Total Validation Loss: 1.313581, Acc: 71.3250\n",
      "Test_: Total Testing Acc: 71.7250\n",
      "Time taken = 1965.9385 s\n",
      "\n",
      "Train: Epoch:17, Batch:19, Loss:0.132406, Acc:93.7500\n",
      "Train: Epoch:17, Batch:39, Loss:0.044292, Acc:96.8750\n",
      "Train: Epoch:17, Batch:59, Loss:0.078885, Acc:96.8750\n",
      "Train: Epoch:17, Batch:79, Loss:0.090516, Acc:96.8750\n",
      "Train: Epoch:17, Batch:99, Loss:0.101864, Acc:96.8750\n",
      "Train: Epoch:17, Batch:119, Loss:0.221591, Acc:87.5000\n",
      "Train: Epoch:17, Batch:139, Loss:0.141140, Acc:93.7500\n",
      "Train: Epoch:17, Batch:159, Loss:0.193903, Acc:87.5000\n",
      "Train: Epoch:17, Batch:179, Loss:0.104374, Acc:93.7500\n",
      "Train: Epoch:17, Batch:199, Loss:0.054081, Acc:100.0000\n",
      "Train: Epoch:17, Batch:219, Loss:0.046109, Acc:100.0000\n",
      "Train: Epoch:17, Batch:239, Loss:0.210558, Acc:93.7500\n",
      "Train: Epoch:17, Batch:259, Loss:0.220401, Acc:90.6250\n",
      "Train: Epoch:17, Batch:279, Loss:0.245991, Acc:90.6250\n",
      "Train: Epoch:17, Batch:299, Loss:0.077005, Acc:100.0000\n",
      "Train: Epoch:17, Batch:319, Loss:0.263441, Acc:90.6250\n",
      "Train: Epoch:17, Batch:339, Loss:0.189707, Acc:90.6250\n",
      "Train: Epoch:17, Batch:359, Loss:0.333781, Acc:87.5000\n",
      "Train: Epoch:17, Batch:379, Loss:0.197241, Acc:93.7500\n",
      "Train: Epoch:17, Batch:399, Loss:0.243230, Acc:93.7500\n",
      "Train: Epoch:17, Batch:419, Loss:0.118060, Acc:96.8750\n",
      "Train: Epoch:17, Batch:439, Loss:0.288705, Acc:87.5000\n",
      "Train: Epoch:17, Batch:459, Loss:0.151471, Acc:96.8750\n",
      "Train: Epoch:17, Batch:479, Loss:0.089497, Acc:93.7500\n",
      "Train: Epoch:17, Batch:499, Loss:0.157425, Acc:90.6250\n",
      "Train: Epoch:17, Batch:519, Loss:0.199155, Acc:93.7500\n",
      "Train: Epoch:17, Batch:539, Loss:0.375452, Acc:87.5000\n",
      "Train: Epoch:17, Batch:559, Loss:0.164908, Acc:87.5000\n",
      "Train: Epoch:17, Batch:579, Loss:0.147907, Acc:90.6250\n",
      "Train: Epoch:17, Batch:599, Loss:0.325644, Acc:81.2500\n",
      "Train: Epoch:17, Batch:619, Loss:0.305851, Acc:87.5000\n",
      "Train: Epoch:17, Batch:639, Loss:0.181491, Acc:90.6250\n",
      "Train: Epoch:17, Batch:659, Loss:0.055382, Acc:100.0000\n",
      "Train: Epoch:17, Batch:679, Loss:0.170361, Acc:93.7500\n",
      "Train: Epoch:17, Batch:699, Loss:0.092874, Acc:100.0000\n",
      "Train: Epoch:17, Batch:719, Loss:0.178258, Acc:90.6250\n",
      "Train: Epoch:17, Batch:739, Loss:0.053642, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.165859, Avg Training Acc: 93.800000\n",
      "Val_: Total Validation Loss: 1.305480, Acc: 72.2250\n",
      "Test_: Total Testing Acc: 72.0375\n",
      "Time taken = 1989.0112 s\n",
      "\n",
      "Train: Epoch:18, Batch:19, Loss:0.123273, Acc:96.8750\n",
      "Train: Epoch:18, Batch:39, Loss:0.097846, Acc:100.0000\n",
      "Train: Epoch:18, Batch:59, Loss:0.136820, Acc:96.8750\n",
      "Train: Epoch:18, Batch:79, Loss:0.059444, Acc:100.0000\n",
      "Train: Epoch:18, Batch:99, Loss:0.182210, Acc:93.7500\n",
      "Train: Epoch:18, Batch:119, Loss:0.021984, Acc:100.0000\n",
      "Train: Epoch:18, Batch:139, Loss:0.073419, Acc:93.7500\n",
      "Train: Epoch:18, Batch:159, Loss:0.139470, Acc:96.8750\n",
      "Train: Epoch:18, Batch:179, Loss:0.059607, Acc:100.0000\n",
      "Train: Epoch:18, Batch:199, Loss:0.027914, Acc:100.0000\n",
      "Train: Epoch:18, Batch:219, Loss:0.057490, Acc:100.0000\n",
      "Train: Epoch:18, Batch:239, Loss:0.071902, Acc:96.8750\n",
      "Train: Epoch:18, Batch:259, Loss:0.242950, Acc:87.5000\n",
      "Train: Epoch:18, Batch:279, Loss:0.167016, Acc:93.7500\n",
      "Train: Epoch:18, Batch:299, Loss:0.203808, Acc:93.7500\n",
      "Train: Epoch:18, Batch:319, Loss:0.079938, Acc:96.8750\n",
      "Train: Epoch:18, Batch:339, Loss:0.261632, Acc:93.7500\n",
      "Train: Epoch:18, Batch:359, Loss:0.234296, Acc:87.5000\n",
      "Train: Epoch:18, Batch:379, Loss:0.164871, Acc:93.7500\n",
      "Train: Epoch:18, Batch:399, Loss:0.119602, Acc:90.6250\n",
      "Train: Epoch:18, Batch:419, Loss:0.231527, Acc:93.7500\n",
      "Train: Epoch:18, Batch:439, Loss:0.137428, Acc:96.8750\n",
      "Train: Epoch:18, Batch:459, Loss:0.181909, Acc:93.7500\n",
      "Train: Epoch:18, Batch:479, Loss:0.103652, Acc:93.7500\n",
      "Train: Epoch:18, Batch:499, Loss:0.258354, Acc:87.5000\n",
      "Train: Epoch:18, Batch:519, Loss:0.163816, Acc:87.5000\n",
      "Train: Epoch:18, Batch:539, Loss:0.165927, Acc:90.6250\n",
      "Train: Epoch:18, Batch:559, Loss:0.125496, Acc:96.8750\n",
      "Train: Epoch:18, Batch:579, Loss:0.124158, Acc:100.0000\n",
      "Train: Epoch:18, Batch:599, Loss:0.195008, Acc:96.8750\n",
      "Train: Epoch:18, Batch:619, Loss:0.331201, Acc:90.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:18, Batch:639, Loss:0.332674, Acc:87.5000\n",
      "Train: Epoch:18, Batch:659, Loss:0.285838, Acc:84.3750\n",
      "Train: Epoch:18, Batch:679, Loss:0.495244, Acc:75.0000\n",
      "Train: Epoch:18, Batch:699, Loss:0.292365, Acc:90.6250\n",
      "Train: Epoch:18, Batch:719, Loss:0.120784, Acc:90.6250\n",
      "Train: Epoch:18, Batch:739, Loss:0.305413, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.150235, Avg Training Acc: 94.433333\n",
      "Val_: Total Validation Loss: 1.381826, Acc: 71.1500\n",
      "Test_: Total Testing Acc: 71.0125\n",
      "Time taken = 1975.9838 s\n",
      "\n",
      "Train: Epoch:19, Batch:19, Loss:0.097245, Acc:96.8750\n",
      "Train: Epoch:19, Batch:39, Loss:0.132470, Acc:96.8750\n",
      "Train: Epoch:19, Batch:59, Loss:0.210798, Acc:90.6250\n",
      "Train: Epoch:19, Batch:79, Loss:0.261459, Acc:90.6250\n",
      "Train: Epoch:19, Batch:99, Loss:0.207239, Acc:87.5000\n",
      "Train: Epoch:19, Batch:119, Loss:0.351924, Acc:90.6250\n",
      "Train: Epoch:19, Batch:139, Loss:0.112347, Acc:90.6250\n",
      "Train: Epoch:19, Batch:159, Loss:0.333171, Acc:87.5000\n",
      "Train: Epoch:19, Batch:179, Loss:0.086099, Acc:96.8750\n",
      "Train: Epoch:19, Batch:199, Loss:0.152218, Acc:93.7500\n",
      "Train: Epoch:19, Batch:219, Loss:0.069485, Acc:96.8750\n",
      "Train: Epoch:19, Batch:239, Loss:0.231458, Acc:93.7500\n",
      "Train: Epoch:19, Batch:259, Loss:0.254209, Acc:84.3750\n",
      "Train: Epoch:19, Batch:279, Loss:0.297519, Acc:87.5000\n",
      "Train: Epoch:19, Batch:299, Loss:0.278935, Acc:90.6250\n",
      "Train: Epoch:19, Batch:319, Loss:0.131436, Acc:93.7500\n",
      "Train: Epoch:19, Batch:339, Loss:0.159945, Acc:90.6250\n",
      "Train: Epoch:19, Batch:359, Loss:0.158011, Acc:96.8750\n",
      "Train: Epoch:19, Batch:379, Loss:0.196878, Acc:87.5000\n",
      "Train: Epoch:19, Batch:399, Loss:0.093833, Acc:96.8750\n",
      "Train: Epoch:19, Batch:419, Loss:0.129824, Acc:90.6250\n",
      "Train: Epoch:19, Batch:439, Loss:0.116537, Acc:93.7500\n",
      "Train: Epoch:19, Batch:459, Loss:0.155981, Acc:87.5000\n",
      "Train: Epoch:19, Batch:479, Loss:0.190144, Acc:93.7500\n",
      "Train: Epoch:19, Batch:499, Loss:0.076474, Acc:96.8750\n",
      "Train: Epoch:19, Batch:519, Loss:0.171056, Acc:93.7500\n",
      "Train: Epoch:19, Batch:539, Loss:0.172131, Acc:93.7500\n",
      "Train: Epoch:19, Batch:559, Loss:0.254714, Acc:90.6250\n",
      "Train: Epoch:19, Batch:579, Loss:0.095704, Acc:96.8750\n",
      "Train: Epoch:19, Batch:599, Loss:0.233310, Acc:93.7500\n",
      "Train: Epoch:19, Batch:619, Loss:0.279960, Acc:96.8750\n",
      "Train: Epoch:19, Batch:639, Loss:0.172030, Acc:93.7500\n",
      "Train: Epoch:19, Batch:659, Loss:0.270180, Acc:87.5000\n",
      "Train: Epoch:19, Batch:679, Loss:0.117674, Acc:93.7500\n",
      "Train: Epoch:19, Batch:699, Loss:0.227444, Acc:96.8750\n",
      "Train: Epoch:19, Batch:719, Loss:0.182426, Acc:90.6250\n",
      "Train: Epoch:19, Batch:739, Loss:0.137070, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.159948, Avg Training Acc: 93.887500\n",
      "Val_: Total Validation Loss: 1.356550, Acc: 71.4750\n",
      "Test_: Total Testing Acc: 71.9375\n",
      "Time taken = 1982.7221 s\n",
      "\n",
      "Train: Epoch:20, Batch:19, Loss:0.085812, Acc:96.8750\n",
      "Train: Epoch:20, Batch:39, Loss:0.170854, Acc:96.8750\n",
      "Train: Epoch:20, Batch:59, Loss:0.118386, Acc:93.7500\n",
      "Train: Epoch:20, Batch:79, Loss:0.099530, Acc:96.8750\n",
      "Train: Epoch:20, Batch:99, Loss:0.061849, Acc:96.8750\n",
      "Train: Epoch:20, Batch:119, Loss:0.066301, Acc:96.8750\n",
      "Train: Epoch:20, Batch:139, Loss:0.061216, Acc:96.8750\n",
      "Train: Epoch:20, Batch:159, Loss:0.094591, Acc:96.8750\n",
      "Train: Epoch:20, Batch:179, Loss:0.038651, Acc:100.0000\n",
      "Train: Epoch:20, Batch:199, Loss:0.302053, Acc:87.5000\n",
      "Train: Epoch:20, Batch:219, Loss:0.023761, Acc:100.0000\n",
      "Train: Epoch:20, Batch:239, Loss:0.263495, Acc:90.6250\n",
      "Train: Epoch:20, Batch:259, Loss:0.226782, Acc:96.8750\n",
      "Train: Epoch:20, Batch:279, Loss:0.157520, Acc:93.7500\n",
      "Train: Epoch:20, Batch:299, Loss:0.030327, Acc:100.0000\n",
      "Train: Epoch:20, Batch:319, Loss:0.151154, Acc:90.6250\n",
      "Train: Epoch:20, Batch:339, Loss:0.221875, Acc:90.6250\n",
      "Train: Epoch:20, Batch:359, Loss:0.212322, Acc:93.7500\n",
      "Train: Epoch:20, Batch:379, Loss:0.377951, Acc:81.2500\n",
      "Train: Epoch:20, Batch:399, Loss:0.248869, Acc:87.5000\n",
      "Train: Epoch:20, Batch:419, Loss:0.055410, Acc:100.0000\n",
      "Train: Epoch:20, Batch:439, Loss:0.133036, Acc:96.8750\n",
      "Train: Epoch:20, Batch:459, Loss:0.825722, Acc:90.6250\n",
      "Train: Epoch:20, Batch:479, Loss:0.174531, Acc:93.7500\n",
      "Train: Epoch:20, Batch:499, Loss:0.147044, Acc:93.7500\n",
      "Train: Epoch:20, Batch:519, Loss:0.310901, Acc:90.6250\n",
      "Train: Epoch:20, Batch:539, Loss:0.453552, Acc:81.2500\n",
      "Train: Epoch:20, Batch:559, Loss:0.099739, Acc:93.7500\n",
      "Train: Epoch:20, Batch:579, Loss:0.120636, Acc:96.8750\n",
      "Train: Epoch:20, Batch:599, Loss:0.212027, Acc:96.8750\n",
      "Train: Epoch:20, Batch:619, Loss:0.279639, Acc:90.6250\n",
      "Train: Epoch:20, Batch:639, Loss:0.216163, Acc:93.7500\n",
      "Train: Epoch:20, Batch:659, Loss:0.143150, Acc:93.7500\n",
      "Train: Epoch:20, Batch:679, Loss:0.149205, Acc:90.6250\n",
      "Train: Epoch:20, Batch:699, Loss:0.102862, Acc:96.8750\n",
      "Train: Epoch:20, Batch:719, Loss:0.159273, Acc:90.6250\n",
      "Train: Epoch:20, Batch:739, Loss:0.252506, Acc:87.5000\n",
      "Train_: Avg Training Loss: 0.159043, Avg Training Acc: 94.025000\n",
      "Val_: Total Validation Loss: 1.361122, Acc: 71.3500\n",
      "Test_: Total Testing Acc: 70.9875\n",
      "Time taken = 1990.7656 s\n",
      "\n",
      "Train: Epoch:21, Batch:19, Loss:0.165508, Acc:90.6250\n",
      "Train: Epoch:21, Batch:39, Loss:0.140480, Acc:93.7500\n",
      "Train: Epoch:21, Batch:59, Loss:0.112724, Acc:93.7500\n",
      "Train: Epoch:21, Batch:79, Loss:0.143676, Acc:93.7500\n",
      "Train: Epoch:21, Batch:99, Loss:0.065873, Acc:96.8750\n",
      "Train: Epoch:21, Batch:119, Loss:0.154863, Acc:93.7500\n",
      "Train: Epoch:21, Batch:139, Loss:0.051707, Acc:100.0000\n",
      "Train: Epoch:21, Batch:159, Loss:0.193207, Acc:90.6250\n",
      "Train: Epoch:21, Batch:179, Loss:0.083725, Acc:96.8750\n",
      "Train: Epoch:21, Batch:199, Loss:0.158847, Acc:96.8750\n",
      "Train: Epoch:21, Batch:219, Loss:0.166226, Acc:93.7500\n",
      "Train: Epoch:21, Batch:239, Loss:0.160614, Acc:87.5000\n",
      "Train: Epoch:21, Batch:259, Loss:0.089763, Acc:100.0000\n",
      "Train: Epoch:21, Batch:279, Loss:0.130402, Acc:93.7500\n",
      "Train: Epoch:21, Batch:299, Loss:0.031357, Acc:100.0000\n",
      "Train: Epoch:21, Batch:319, Loss:0.084622, Acc:96.8750\n",
      "Train: Epoch:21, Batch:339, Loss:0.041810, Acc:100.0000\n",
      "Train: Epoch:21, Batch:359, Loss:0.073881, Acc:96.8750\n",
      "Train: Epoch:21, Batch:379, Loss:0.076105, Acc:96.8750\n",
      "Train: Epoch:21, Batch:399, Loss:0.094313, Acc:96.8750\n",
      "Train: Epoch:21, Batch:419, Loss:0.349149, Acc:90.6250\n",
      "Train: Epoch:21, Batch:439, Loss:0.096214, Acc:93.7500\n",
      "Train: Epoch:21, Batch:459, Loss:0.065163, Acc:96.8750\n",
      "Train: Epoch:21, Batch:479, Loss:0.073219, Acc:96.8750\n",
      "Train: Epoch:21, Batch:499, Loss:0.157915, Acc:90.6250\n",
      "Train: Epoch:21, Batch:519, Loss:0.071030, Acc:96.8750\n",
      "Train: Epoch:21, Batch:539, Loss:0.047142, Acc:100.0000\n",
      "Train: Epoch:21, Batch:559, Loss:0.098901, Acc:96.8750\n",
      "Train: Epoch:21, Batch:579, Loss:0.422423, Acc:90.6250\n",
      "Train: Epoch:21, Batch:599, Loss:0.082963, Acc:96.8750\n",
      "Train: Epoch:21, Batch:619, Loss:0.115835, Acc:93.7500\n",
      "Train: Epoch:21, Batch:639, Loss:0.022976, Acc:100.0000\n",
      "Train: Epoch:21, Batch:659, Loss:0.060460, Acc:100.0000\n",
      "Train: Epoch:21, Batch:679, Loss:0.257330, Acc:90.6250\n",
      "Train: Epoch:21, Batch:699, Loss:0.115757, Acc:93.7500\n",
      "Train: Epoch:21, Batch:719, Loss:0.152256, Acc:96.8750\n",
      "Train: Epoch:21, Batch:739, Loss:0.028985, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.140356, Avg Training Acc: 94.637500\n",
      "Val_: Total Validation Loss: 1.363151, Acc: 72.1875\n",
      "Test_: Total Testing Acc: 71.9125\n",
      "Time taken = 1953.0081 s\n",
      "\n",
      "Train: Epoch:22, Batch:19, Loss:0.066992, Acc:100.0000\n",
      "Train: Epoch:22, Batch:39, Loss:0.121889, Acc:93.7500\n",
      "Train: Epoch:22, Batch:59, Loss:0.176038, Acc:93.7500\n",
      "Train: Epoch:22, Batch:79, Loss:0.137448, Acc:93.7500\n",
      "Train: Epoch:22, Batch:99, Loss:0.154509, Acc:93.7500\n",
      "Train: Epoch:22, Batch:119, Loss:0.111123, Acc:100.0000\n",
      "Train: Epoch:22, Batch:139, Loss:0.119069, Acc:96.8750\n",
      "Train: Epoch:22, Batch:159, Loss:0.288165, Acc:93.7500\n",
      "Train: Epoch:22, Batch:179, Loss:0.063966, Acc:96.8750\n",
      "Train: Epoch:22, Batch:199, Loss:0.057910, Acc:96.8750\n",
      "Train: Epoch:22, Batch:219, Loss:0.247597, Acc:93.7500\n",
      "Train: Epoch:22, Batch:239, Loss:0.092675, Acc:96.8750\n",
      "Train: Epoch:22, Batch:259, Loss:0.098010, Acc:96.8750\n",
      "Train: Epoch:22, Batch:279, Loss:0.090353, Acc:100.0000\n",
      "Train: Epoch:22, Batch:299, Loss:0.111146, Acc:96.8750\n",
      "Train: Epoch:22, Batch:319, Loss:0.181899, Acc:90.6250\n",
      "Train: Epoch:22, Batch:339, Loss:0.073824, Acc:100.0000\n",
      "Train: Epoch:22, Batch:359, Loss:0.251038, Acc:90.6250\n",
      "Train: Epoch:22, Batch:379, Loss:0.052229, Acc:100.0000\n",
      "Train: Epoch:22, Batch:399, Loss:0.158312, Acc:93.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:22, Batch:419, Loss:0.181130, Acc:96.8750\n",
      "Train: Epoch:22, Batch:439, Loss:0.254747, Acc:90.6250\n",
      "Train: Epoch:22, Batch:459, Loss:0.454616, Acc:87.5000\n",
      "Train: Epoch:22, Batch:479, Loss:0.047552, Acc:100.0000\n",
      "Train: Epoch:22, Batch:499, Loss:0.369806, Acc:87.5000\n",
      "Train: Epoch:22, Batch:519, Loss:0.168620, Acc:93.7500\n",
      "Train: Epoch:22, Batch:539, Loss:0.446574, Acc:90.6250\n",
      "Train: Epoch:22, Batch:559, Loss:0.308873, Acc:93.7500\n",
      "Train: Epoch:22, Batch:579, Loss:0.136470, Acc:96.8750\n",
      "Train: Epoch:22, Batch:599, Loss:0.202033, Acc:93.7500\n",
      "Train: Epoch:22, Batch:619, Loss:0.119431, Acc:96.8750\n",
      "Train: Epoch:22, Batch:639, Loss:0.081231, Acc:100.0000\n",
      "Train: Epoch:22, Batch:659, Loss:0.103586, Acc:100.0000\n",
      "Train: Epoch:22, Batch:679, Loss:0.073002, Acc:96.8750\n",
      "Train: Epoch:22, Batch:699, Loss:0.061366, Acc:96.8750\n",
      "Train: Epoch:22, Batch:719, Loss:0.151589, Acc:90.6250\n",
      "Train: Epoch:22, Batch:739, Loss:0.236522, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.161450, Avg Training Acc: 94.220833\n",
      "Val_: Total Validation Loss: 1.437604, Acc: 71.2750\n",
      "Test_: Total Testing Acc: 71.8375\n",
      "Time taken = 1963.9771 s\n",
      "\n",
      "Train: Epoch:23, Batch:19, Loss:0.035773, Acc:96.8750\n",
      "Train: Epoch:23, Batch:39, Loss:0.184986, Acc:87.5000\n",
      "Train: Epoch:23, Batch:59, Loss:0.272349, Acc:90.6250\n",
      "Train: Epoch:23, Batch:79, Loss:0.105991, Acc:93.7500\n",
      "Train: Epoch:23, Batch:99, Loss:0.390291, Acc:93.7500\n",
      "Train: Epoch:23, Batch:119, Loss:0.098516, Acc:96.8750\n",
      "Train: Epoch:23, Batch:139, Loss:0.160220, Acc:90.6250\n",
      "Train: Epoch:23, Batch:159, Loss:0.140089, Acc:96.8750\n",
      "Train: Epoch:23, Batch:179, Loss:0.121910, Acc:93.7500\n",
      "Train: Epoch:23, Batch:199, Loss:0.147063, Acc:96.8750\n",
      "Train: Epoch:23, Batch:219, Loss:0.100137, Acc:96.8750\n",
      "Train: Epoch:23, Batch:239, Loss:0.106755, Acc:93.7500\n",
      "Train: Epoch:23, Batch:259, Loss:0.112415, Acc:96.8750\n",
      "Train: Epoch:23, Batch:279, Loss:0.094833, Acc:93.7500\n",
      "Train: Epoch:23, Batch:299, Loss:0.113926, Acc:93.7500\n",
      "Train: Epoch:23, Batch:319, Loss:0.231700, Acc:93.7500\n",
      "Train: Epoch:23, Batch:339, Loss:0.101237, Acc:93.7500\n",
      "Train: Epoch:23, Batch:359, Loss:0.395294, Acc:81.2500\n",
      "Train: Epoch:23, Batch:379, Loss:0.213887, Acc:90.6250\n",
      "Train: Epoch:23, Batch:399, Loss:0.263906, Acc:93.7500\n",
      "Train: Epoch:23, Batch:419, Loss:0.150674, Acc:90.6250\n",
      "Train: Epoch:23, Batch:439, Loss:0.183886, Acc:90.6250\n",
      "Train: Epoch:23, Batch:459, Loss:0.029446, Acc:100.0000\n",
      "Train: Epoch:23, Batch:479, Loss:0.405921, Acc:87.5000\n",
      "Train: Epoch:23, Batch:499, Loss:0.137424, Acc:93.7500\n",
      "Train: Epoch:23, Batch:519, Loss:0.034784, Acc:100.0000\n",
      "Train: Epoch:23, Batch:539, Loss:0.258847, Acc:87.5000\n",
      "Train: Epoch:23, Batch:559, Loss:0.071237, Acc:96.8750\n",
      "Train: Epoch:23, Batch:579, Loss:0.500139, Acc:81.2500\n",
      "Train: Epoch:23, Batch:599, Loss:0.226926, Acc:87.5000\n",
      "Train: Epoch:23, Batch:619, Loss:0.193526, Acc:96.8750\n",
      "Train: Epoch:23, Batch:639, Loss:0.147259, Acc:96.8750\n",
      "Train: Epoch:23, Batch:659, Loss:0.056561, Acc:100.0000\n",
      "Train: Epoch:23, Batch:679, Loss:0.064647, Acc:100.0000\n",
      "Train: Epoch:23, Batch:699, Loss:0.228495, Acc:87.5000\n",
      "Train: Epoch:23, Batch:719, Loss:0.117838, Acc:96.8750\n",
      "Train: Epoch:23, Batch:739, Loss:0.039464, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.152067, Avg Training Acc: 94.433333\n",
      "Val_: Total Validation Loss: 1.336139, Acc: 71.6250\n",
      "Test_: Total Testing Acc: 71.6875\n",
      "Time taken = 1960.4859 s\n",
      "\n",
      "Train: Epoch:24, Batch:19, Loss:0.055709, Acc:100.0000\n",
      "Train: Epoch:24, Batch:39, Loss:0.099890, Acc:96.8750\n",
      "Train: Epoch:24, Batch:59, Loss:0.124184, Acc:96.8750\n",
      "Train: Epoch:24, Batch:79, Loss:0.099112, Acc:93.7500\n",
      "Train: Epoch:24, Batch:99, Loss:0.279612, Acc:90.6250\n",
      "Train: Epoch:24, Batch:119, Loss:0.026785, Acc:100.0000\n",
      "Train: Epoch:24, Batch:139, Loss:0.035643, Acc:100.0000\n",
      "Train: Epoch:24, Batch:159, Loss:0.149675, Acc:93.7500\n",
      "Train: Epoch:24, Batch:179, Loss:0.101984, Acc:96.8750\n",
      "Train: Epoch:24, Batch:199, Loss:0.140169, Acc:90.6250\n",
      "Train: Epoch:24, Batch:219, Loss:0.087764, Acc:93.7500\n",
      "Train: Epoch:24, Batch:239, Loss:0.047677, Acc:100.0000\n",
      "Train: Epoch:24, Batch:259, Loss:0.064351, Acc:96.8750\n",
      "Train: Epoch:24, Batch:279, Loss:0.096320, Acc:96.8750\n",
      "Train: Epoch:24, Batch:299, Loss:0.056544, Acc:100.0000\n",
      "Train: Epoch:24, Batch:319, Loss:0.035907, Acc:100.0000\n",
      "Train: Epoch:24, Batch:339, Loss:0.012146, Acc:100.0000\n",
      "Train: Epoch:24, Batch:359, Loss:0.199548, Acc:90.6250\n",
      "Train: Epoch:24, Batch:379, Loss:0.499429, Acc:87.5000\n",
      "Train: Epoch:24, Batch:399, Loss:0.125027, Acc:96.8750\n",
      "Train: Epoch:24, Batch:419, Loss:0.161984, Acc:96.8750\n",
      "Train: Epoch:24, Batch:439, Loss:0.103287, Acc:96.8750\n",
      "Train: Epoch:24, Batch:459, Loss:0.065209, Acc:100.0000\n",
      "Train: Epoch:24, Batch:479, Loss:0.058974, Acc:100.0000\n",
      "Train: Epoch:24, Batch:499, Loss:0.209286, Acc:90.6250\n",
      "Train: Epoch:24, Batch:519, Loss:0.142304, Acc:96.8750\n",
      "Train: Epoch:24, Batch:539, Loss:0.145806, Acc:93.7500\n",
      "Train: Epoch:24, Batch:559, Loss:0.210546, Acc:90.6250\n",
      "Train: Epoch:24, Batch:579, Loss:0.059287, Acc:100.0000\n",
      "Train: Epoch:24, Batch:599, Loss:0.275381, Acc:90.6250\n",
      "Train: Epoch:24, Batch:619, Loss:0.108136, Acc:96.8750\n",
      "Train: Epoch:24, Batch:639, Loss:0.121388, Acc:96.8750\n",
      "Train: Epoch:24, Batch:659, Loss:0.206530, Acc:87.5000\n",
      "Train: Epoch:24, Batch:679, Loss:0.073921, Acc:96.8750\n",
      "Train: Epoch:24, Batch:699, Loss:0.126395, Acc:96.8750\n",
      "Train: Epoch:24, Batch:719, Loss:0.069600, Acc:96.8750\n",
      "Train: Epoch:24, Batch:739, Loss:0.119781, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.143652, Avg Training Acc: 94.733333\n",
      "Val_: Total Validation Loss: 1.395502, Acc: 71.6375\n",
      "Test_: Total Testing Acc: 71.7625\n",
      "Time taken = 1989.3540 s\n",
      "\n",
      "Train: Epoch:25, Batch:19, Loss:0.039810, Acc:96.8750\n",
      "Train: Epoch:25, Batch:39, Loss:0.182665, Acc:90.6250\n",
      "Train: Epoch:25, Batch:59, Loss:0.071963, Acc:96.8750\n",
      "Train: Epoch:25, Batch:79, Loss:0.055998, Acc:100.0000\n",
      "Train: Epoch:25, Batch:99, Loss:0.065439, Acc:100.0000\n",
      "Train: Epoch:25, Batch:119, Loss:0.052147, Acc:100.0000\n",
      "Train: Epoch:25, Batch:139, Loss:0.078325, Acc:96.8750\n",
      "Train: Epoch:25, Batch:159, Loss:0.315740, Acc:96.8750\n",
      "Train: Epoch:25, Batch:179, Loss:0.060477, Acc:96.8750\n",
      "Train: Epoch:25, Batch:199, Loss:0.143999, Acc:90.6250\n",
      "Train: Epoch:25, Batch:219, Loss:0.119502, Acc:93.7500\n",
      "Train: Epoch:25, Batch:239, Loss:0.168776, Acc:90.6250\n",
      "Train: Epoch:25, Batch:259, Loss:0.073824, Acc:96.8750\n",
      "Train: Epoch:25, Batch:279, Loss:0.063121, Acc:100.0000\n",
      "Train: Epoch:25, Batch:299, Loss:0.063272, Acc:96.8750\n",
      "Train: Epoch:25, Batch:319, Loss:0.200741, Acc:90.6250\n",
      "Train: Epoch:25, Batch:339, Loss:0.212458, Acc:96.8750\n",
      "Train: Epoch:25, Batch:359, Loss:0.133546, Acc:90.6250\n",
      "Train: Epoch:25, Batch:379, Loss:0.090749, Acc:96.8750\n",
      "Train: Epoch:25, Batch:399, Loss:0.187411, Acc:93.7500\n",
      "Train: Epoch:25, Batch:419, Loss:0.304240, Acc:93.7500\n",
      "Train: Epoch:25, Batch:439, Loss:0.056103, Acc:100.0000\n",
      "Train: Epoch:25, Batch:459, Loss:0.249972, Acc:87.5000\n",
      "Train: Epoch:25, Batch:479, Loss:0.169025, Acc:93.7500\n",
      "Train: Epoch:25, Batch:499, Loss:0.319944, Acc:87.5000\n",
      "Train: Epoch:25, Batch:519, Loss:0.334519, Acc:90.6250\n",
      "Train: Epoch:25, Batch:539, Loss:0.148921, Acc:90.6250\n",
      "Train: Epoch:25, Batch:559, Loss:0.242793, Acc:90.6250\n",
      "Train: Epoch:25, Batch:579, Loss:0.266453, Acc:84.3750\n",
      "Train: Epoch:25, Batch:599, Loss:0.097995, Acc:96.8750\n",
      "Train: Epoch:25, Batch:619, Loss:0.152719, Acc:93.7500\n",
      "Train: Epoch:25, Batch:639, Loss:0.125858, Acc:96.8750\n",
      "Train: Epoch:25, Batch:659, Loss:0.179376, Acc:90.6250\n",
      "Train: Epoch:25, Batch:679, Loss:0.067074, Acc:100.0000\n",
      "Train: Epoch:25, Batch:699, Loss:0.111801, Acc:96.8750\n",
      "Train: Epoch:25, Batch:719, Loss:0.011053, Acc:100.0000\n",
      "Train: Epoch:25, Batch:739, Loss:0.111386, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.157415, Avg Training Acc: 94.141667\n",
      "Val_: Total Validation Loss: 1.463827, Acc: 69.7875\n",
      "Test_: Total Testing Acc: 70.0125\n",
      "Time taken = 1957.6189 s\n",
      "\n",
      "Train: Epoch:26, Batch:19, Loss:0.223197, Acc:87.5000\n",
      "Train: Epoch:26, Batch:39, Loss:0.080090, Acc:96.8750\n",
      "Train: Epoch:26, Batch:59, Loss:0.252795, Acc:90.6250\n",
      "Train: Epoch:26, Batch:79, Loss:0.124434, Acc:96.8750\n",
      "Train: Epoch:26, Batch:99, Loss:0.124317, Acc:96.8750\n",
      "Train: Epoch:26, Batch:119, Loss:0.097128, Acc:96.8750\n",
      "Train: Epoch:26, Batch:139, Loss:0.177880, Acc:96.8750\n",
      "Train: Epoch:26, Batch:159, Loss:0.075900, Acc:96.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:26, Batch:179, Loss:0.126661, Acc:93.7500\n",
      "Train: Epoch:26, Batch:199, Loss:0.098232, Acc:96.8750\n",
      "Train: Epoch:26, Batch:219, Loss:0.081156, Acc:96.8750\n",
      "Train: Epoch:26, Batch:239, Loss:0.095217, Acc:100.0000\n",
      "Train: Epoch:26, Batch:259, Loss:0.064225, Acc:96.8750\n",
      "Train: Epoch:26, Batch:279, Loss:0.014909, Acc:100.0000\n",
      "Train: Epoch:26, Batch:299, Loss:0.174628, Acc:93.7500\n",
      "Train: Epoch:26, Batch:319, Loss:0.063786, Acc:100.0000\n",
      "Train: Epoch:26, Batch:339, Loss:0.100670, Acc:96.8750\n",
      "Train: Epoch:26, Batch:359, Loss:0.023455, Acc:100.0000\n",
      "Train: Epoch:26, Batch:379, Loss:0.050989, Acc:100.0000\n",
      "Train: Epoch:26, Batch:399, Loss:0.117167, Acc:90.6250\n",
      "Train: Epoch:26, Batch:419, Loss:0.167161, Acc:93.7500\n",
      "Train: Epoch:26, Batch:439, Loss:0.075763, Acc:96.8750\n",
      "Train: Epoch:26, Batch:459, Loss:0.168913, Acc:87.5000\n",
      "Train: Epoch:26, Batch:479, Loss:0.110947, Acc:100.0000\n",
      "Train: Epoch:26, Batch:499, Loss:0.344967, Acc:93.7500\n",
      "Train: Epoch:26, Batch:519, Loss:0.173951, Acc:93.7500\n",
      "Train: Epoch:26, Batch:539, Loss:0.067901, Acc:96.8750\n",
      "Train: Epoch:26, Batch:559, Loss:0.095851, Acc:93.7500\n",
      "Train: Epoch:26, Batch:579, Loss:0.201855, Acc:93.7500\n",
      "Train: Epoch:26, Batch:599, Loss:0.158811, Acc:93.7500\n",
      "Train: Epoch:26, Batch:619, Loss:0.046812, Acc:100.0000\n",
      "Train: Epoch:26, Batch:639, Loss:0.232417, Acc:93.7500\n",
      "Train: Epoch:26, Batch:659, Loss:0.323571, Acc:87.5000\n",
      "Train: Epoch:26, Batch:679, Loss:0.096484, Acc:96.8750\n",
      "Train: Epoch:26, Batch:699, Loss:0.092055, Acc:96.8750\n",
      "Train: Epoch:26, Batch:719, Loss:0.106647, Acc:100.0000\n",
      "Train: Epoch:26, Batch:739, Loss:0.157516, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.125628, Avg Training Acc: 95.341667\n",
      "Val_: Total Validation Loss: 1.427628, Acc: 71.5750\n",
      "Test_: Total Testing Acc: 71.6625\n",
      "Time taken = 1964.5624 s\n",
      "\n",
      "Train: Epoch:27, Batch:19, Loss:0.313609, Acc:87.5000\n",
      "Train: Epoch:27, Batch:39, Loss:0.074508, Acc:96.8750\n",
      "Train: Epoch:27, Batch:59, Loss:0.150532, Acc:96.8750\n",
      "Train: Epoch:27, Batch:79, Loss:0.028742, Acc:100.0000\n",
      "Train: Epoch:27, Batch:99, Loss:0.082975, Acc:93.7500\n",
      "Train: Epoch:27, Batch:119, Loss:0.239978, Acc:84.3750\n",
      "Train: Epoch:27, Batch:139, Loss:0.173876, Acc:93.7500\n",
      "Train: Epoch:27, Batch:159, Loss:0.177402, Acc:87.5000\n",
      "Train: Epoch:27, Batch:179, Loss:0.215683, Acc:90.6250\n",
      "Train: Epoch:27, Batch:199, Loss:0.057949, Acc:100.0000\n",
      "Train: Epoch:27, Batch:219, Loss:0.122794, Acc:96.8750\n",
      "Train: Epoch:27, Batch:239, Loss:0.202094, Acc:87.5000\n",
      "Train: Epoch:27, Batch:259, Loss:0.109434, Acc:93.7500\n",
      "Train: Epoch:27, Batch:279, Loss:0.148026, Acc:96.8750\n",
      "Train: Epoch:27, Batch:299, Loss:0.079253, Acc:96.8750\n",
      "Train: Epoch:27, Batch:319, Loss:0.100629, Acc:96.8750\n",
      "Train: Epoch:27, Batch:339, Loss:0.371137, Acc:87.5000\n",
      "Train: Epoch:27, Batch:359, Loss:0.341000, Acc:84.3750\n",
      "Train: Epoch:27, Batch:379, Loss:0.105926, Acc:96.8750\n",
      "Train: Epoch:27, Batch:399, Loss:0.123557, Acc:90.6250\n",
      "Train: Epoch:27, Batch:419, Loss:0.193757, Acc:93.7500\n",
      "Train: Epoch:27, Batch:439, Loss:0.188477, Acc:90.6250\n",
      "Train: Epoch:27, Batch:459, Loss:0.097288, Acc:96.8750\n",
      "Train: Epoch:27, Batch:479, Loss:0.143508, Acc:90.6250\n",
      "Train: Epoch:27, Batch:499, Loss:0.131835, Acc:93.7500\n",
      "Train: Epoch:27, Batch:519, Loss:0.169647, Acc:96.8750\n",
      "Train: Epoch:27, Batch:539, Loss:0.068026, Acc:96.8750\n",
      "Train: Epoch:27, Batch:559, Loss:0.064686, Acc:100.0000\n",
      "Train: Epoch:27, Batch:579, Loss:0.082606, Acc:93.7500\n",
      "Train: Epoch:27, Batch:599, Loss:0.369552, Acc:87.5000\n",
      "Train: Epoch:27, Batch:619, Loss:0.126857, Acc:96.8750\n",
      "Train: Epoch:27, Batch:639, Loss:0.093833, Acc:96.8750\n",
      "Train: Epoch:27, Batch:659, Loss:0.047468, Acc:96.8750\n",
      "Train: Epoch:27, Batch:679, Loss:0.148032, Acc:93.7500\n",
      "Train: Epoch:27, Batch:699, Loss:0.260553, Acc:90.6250\n",
      "Train: Epoch:27, Batch:719, Loss:0.164468, Acc:90.6250\n",
      "Train: Epoch:27, Batch:739, Loss:0.156122, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.138797, Avg Training Acc: 94.766667\n",
      "Val_: Total Validation Loss: 1.478228, Acc: 71.9625\n",
      "Test_: Total Testing Acc: 70.9500\n",
      "Time taken = 1996.9403 s\n",
      "\n",
      "Train: Epoch:28, Batch:19, Loss:0.094409, Acc:96.8750\n",
      "Train: Epoch:28, Batch:39, Loss:0.180577, Acc:90.6250\n",
      "Train: Epoch:28, Batch:59, Loss:0.186775, Acc:90.6250\n",
      "Train: Epoch:28, Batch:79, Loss:0.236420, Acc:90.6250\n",
      "Train: Epoch:28, Batch:99, Loss:0.150483, Acc:93.7500\n",
      "Train: Epoch:28, Batch:119, Loss:0.092365, Acc:96.8750\n",
      "Train: Epoch:28, Batch:139, Loss:0.179506, Acc:90.6250\n",
      "Train: Epoch:28, Batch:159, Loss:0.189408, Acc:90.6250\n",
      "Train: Epoch:28, Batch:179, Loss:0.059152, Acc:96.8750\n",
      "Train: Epoch:28, Batch:199, Loss:0.075504, Acc:96.8750\n",
      "Train: Epoch:28, Batch:219, Loss:0.155171, Acc:93.7500\n",
      "Train: Epoch:28, Batch:239, Loss:0.453113, Acc:78.1250\n",
      "Train: Epoch:28, Batch:259, Loss:0.097687, Acc:93.7500\n",
      "Train: Epoch:28, Batch:279, Loss:0.152697, Acc:93.7500\n",
      "Train: Epoch:28, Batch:299, Loss:0.129356, Acc:96.8750\n",
      "Train: Epoch:28, Batch:319, Loss:0.120509, Acc:93.7500\n",
      "Train: Epoch:28, Batch:339, Loss:0.031591, Acc:100.0000\n",
      "Train: Epoch:28, Batch:359, Loss:0.033136, Acc:100.0000\n",
      "Train: Epoch:28, Batch:379, Loss:0.156694, Acc:90.6250\n",
      "Train: Epoch:28, Batch:399, Loss:0.160927, Acc:93.7500\n",
      "Train: Epoch:28, Batch:419, Loss:0.058687, Acc:96.8750\n",
      "Train: Epoch:28, Batch:439, Loss:0.080529, Acc:96.8750\n",
      "Train: Epoch:28, Batch:459, Loss:0.068412, Acc:100.0000\n",
      "Train: Epoch:28, Batch:479, Loss:0.144455, Acc:96.8750\n",
      "Train: Epoch:28, Batch:499, Loss:0.121994, Acc:93.7500\n",
      "Train: Epoch:28, Batch:519, Loss:0.058635, Acc:96.8750\n",
      "Train: Epoch:28, Batch:539, Loss:0.224555, Acc:90.6250\n",
      "Train: Epoch:28, Batch:559, Loss:0.352650, Acc:84.3750\n",
      "Train: Epoch:28, Batch:579, Loss:0.069381, Acc:96.8750\n",
      "Train: Epoch:28, Batch:599, Loss:0.085988, Acc:96.8750\n",
      "Train: Epoch:28, Batch:619, Loss:0.144177, Acc:93.7500\n",
      "Train: Epoch:28, Batch:639, Loss:0.357331, Acc:90.6250\n",
      "Train: Epoch:28, Batch:659, Loss:0.195031, Acc:90.6250\n",
      "Train: Epoch:28, Batch:679, Loss:0.075956, Acc:100.0000\n",
      "Train: Epoch:28, Batch:699, Loss:0.326259, Acc:84.3750\n",
      "Train: Epoch:28, Batch:719, Loss:0.308221, Acc:93.7500\n",
      "Train: Epoch:28, Batch:739, Loss:0.069037, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.140046, Avg Training Acc: 94.641667\n",
      "Val_: Total Validation Loss: 1.472036, Acc: 71.4250\n",
      "Test_: Total Testing Acc: 71.2250\n",
      "Time taken = 1962.0038 s\n",
      "\n",
      "Train: Epoch:29, Batch:19, Loss:0.243854, Acc:96.8750\n",
      "Train: Epoch:29, Batch:39, Loss:0.105908, Acc:96.8750\n",
      "Train: Epoch:29, Batch:59, Loss:0.066939, Acc:100.0000\n",
      "Train: Epoch:29, Batch:79, Loss:0.042853, Acc:96.8750\n",
      "Train: Epoch:29, Batch:99, Loss:0.135383, Acc:96.8750\n",
      "Train: Epoch:29, Batch:119, Loss:0.154715, Acc:96.8750\n",
      "Train: Epoch:29, Batch:139, Loss:0.081358, Acc:96.8750\n",
      "Train: Epoch:29, Batch:159, Loss:0.095805, Acc:96.8750\n",
      "Train: Epoch:29, Batch:179, Loss:0.106066, Acc:93.7500\n",
      "Train: Epoch:29, Batch:199, Loss:0.321401, Acc:90.6250\n",
      "Train: Epoch:29, Batch:219, Loss:0.103490, Acc:96.8750\n",
      "Train: Epoch:29, Batch:239, Loss:0.165855, Acc:93.7500\n",
      "Train: Epoch:29, Batch:259, Loss:0.349487, Acc:90.6250\n",
      "Train: Epoch:29, Batch:279, Loss:0.241050, Acc:90.6250\n",
      "Train: Epoch:29, Batch:299, Loss:0.158514, Acc:96.8750\n",
      "Train: Epoch:29, Batch:319, Loss:0.212554, Acc:90.6250\n",
      "Train: Epoch:29, Batch:339, Loss:0.019615, Acc:100.0000\n",
      "Train: Epoch:29, Batch:359, Loss:0.215197, Acc:87.5000\n",
      "Train: Epoch:29, Batch:379, Loss:0.273921, Acc:87.5000\n",
      "Train: Epoch:29, Batch:399, Loss:0.114468, Acc:96.8750\n",
      "Train: Epoch:29, Batch:419, Loss:0.319326, Acc:90.6250\n",
      "Train: Epoch:29, Batch:439, Loss:0.021485, Acc:100.0000\n",
      "Train: Epoch:29, Batch:459, Loss:0.110600, Acc:96.8750\n",
      "Train: Epoch:29, Batch:479, Loss:0.150616, Acc:90.6250\n",
      "Train: Epoch:29, Batch:499, Loss:0.203630, Acc:90.6250\n",
      "Train: Epoch:29, Batch:519, Loss:0.131324, Acc:96.8750\n",
      "Train: Epoch:29, Batch:539, Loss:0.038383, Acc:100.0000\n",
      "Train: Epoch:29, Batch:559, Loss:0.112598, Acc:93.7500\n",
      "Train: Epoch:29, Batch:579, Loss:0.079574, Acc:100.0000\n",
      "Train: Epoch:29, Batch:599, Loss:0.121375, Acc:96.8750\n",
      "Train: Epoch:29, Batch:619, Loss:0.096332, Acc:100.0000\n",
      "Train: Epoch:29, Batch:639, Loss:0.035898, Acc:100.0000\n",
      "Train: Epoch:29, Batch:659, Loss:0.214790, Acc:87.5000\n",
      "Train: Epoch:29, Batch:679, Loss:0.289730, Acc:84.3750\n",
      "Train: Epoch:29, Batch:699, Loss:0.247117, Acc:96.8750\n",
      "Train: Epoch:29, Batch:719, Loss:0.234134, Acc:93.7500\n",
      "Train: Epoch:29, Batch:739, Loss:0.177477, Acc:93.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_: Avg Training Loss: 0.134692, Avg Training Acc: 95.179167\n",
      "Val_: Total Validation Loss: 1.520793, Acc: 71.3000\n",
      "Test_: Total Testing Acc: 69.9125\n",
      "Time taken = 1954.3317 s\n",
      "\n",
      "Train: Epoch:30, Batch:19, Loss:0.012916, Acc:100.0000\n",
      "Train: Epoch:30, Batch:39, Loss:0.155400, Acc:93.7500\n",
      "Train: Epoch:30, Batch:59, Loss:0.077361, Acc:93.7500\n",
      "Train: Epoch:30, Batch:79, Loss:0.127768, Acc:93.7500\n",
      "Train: Epoch:30, Batch:99, Loss:0.210140, Acc:90.6250\n",
      "Train: Epoch:30, Batch:119, Loss:0.087176, Acc:96.8750\n",
      "Train: Epoch:30, Batch:139, Loss:0.300023, Acc:90.6250\n",
      "Train: Epoch:30, Batch:159, Loss:0.097147, Acc:96.8750\n",
      "Train: Epoch:30, Batch:179, Loss:0.314534, Acc:84.3750\n",
      "Train: Epoch:30, Batch:199, Loss:0.132021, Acc:90.6250\n",
      "Train: Epoch:30, Batch:219, Loss:0.112645, Acc:93.7500\n",
      "Train: Epoch:30, Batch:239, Loss:0.187866, Acc:90.6250\n",
      "Train: Epoch:30, Batch:259, Loss:0.087659, Acc:96.8750\n",
      "Train: Epoch:30, Batch:279, Loss:0.109575, Acc:90.6250\n",
      "Train: Epoch:30, Batch:299, Loss:0.100566, Acc:93.7500\n",
      "Train: Epoch:30, Batch:319, Loss:0.244560, Acc:87.5000\n",
      "Train: Epoch:30, Batch:339, Loss:0.219698, Acc:90.6250\n",
      "Train: Epoch:30, Batch:359, Loss:0.218573, Acc:93.7500\n",
      "Train: Epoch:30, Batch:379, Loss:0.125044, Acc:96.8750\n",
      "Train: Epoch:30, Batch:399, Loss:0.044963, Acc:100.0000\n",
      "Train: Epoch:30, Batch:419, Loss:0.063938, Acc:100.0000\n",
      "Train: Epoch:30, Batch:439, Loss:0.097424, Acc:93.7500\n",
      "Train: Epoch:30, Batch:459, Loss:0.050880, Acc:100.0000\n",
      "Train: Epoch:30, Batch:479, Loss:0.130286, Acc:90.6250\n",
      "Train: Epoch:30, Batch:499, Loss:0.088640, Acc:96.8750\n",
      "Train: Epoch:30, Batch:519, Loss:0.281508, Acc:87.5000\n",
      "Train: Epoch:30, Batch:539, Loss:0.128492, Acc:100.0000\n",
      "Train: Epoch:30, Batch:559, Loss:0.016719, Acc:100.0000\n",
      "Train: Epoch:30, Batch:579, Loss:0.200933, Acc:93.7500\n",
      "Train: Epoch:30, Batch:599, Loss:0.145845, Acc:96.8750\n",
      "Train: Epoch:30, Batch:619, Loss:0.151379, Acc:93.7500\n",
      "Train: Epoch:30, Batch:639, Loss:0.086940, Acc:93.7500\n",
      "Train: Epoch:30, Batch:659, Loss:0.114862, Acc:93.7500\n",
      "Train: Epoch:30, Batch:679, Loss:0.368891, Acc:87.5000\n",
      "Train: Epoch:30, Batch:699, Loss:0.188227, Acc:90.6250\n",
      "Train: Epoch:30, Batch:719, Loss:0.285698, Acc:90.6250\n",
      "Train: Epoch:30, Batch:739, Loss:0.187868, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.143065, Avg Training Acc: 94.758333\n",
      "Val_: Total Validation Loss: 1.448987, Acc: 71.8125\n",
      "Test_: Total Testing Acc: 70.9000\n",
      "Time taken = 1962.1669 s\n",
      "\n",
      "Train: Epoch:31, Batch:19, Loss:0.261332, Acc:93.7500\n",
      "Train: Epoch:31, Batch:39, Loss:0.112013, Acc:96.8750\n",
      "Train: Epoch:31, Batch:59, Loss:0.124808, Acc:93.7500\n",
      "Train: Epoch:31, Batch:79, Loss:0.053466, Acc:100.0000\n",
      "Train: Epoch:31, Batch:99, Loss:0.045543, Acc:100.0000\n",
      "Train: Epoch:31, Batch:119, Loss:0.078463, Acc:96.8750\n",
      "Train: Epoch:31, Batch:139, Loss:0.218978, Acc:90.6250\n",
      "Train: Epoch:31, Batch:159, Loss:0.114268, Acc:100.0000\n",
      "Train: Epoch:31, Batch:179, Loss:0.081151, Acc:96.8750\n",
      "Train: Epoch:31, Batch:199, Loss:0.049800, Acc:100.0000\n",
      "Train: Epoch:31, Batch:219, Loss:0.038896, Acc:96.8750\n",
      "Train: Epoch:31, Batch:239, Loss:0.179115, Acc:96.8750\n",
      "Train: Epoch:31, Batch:259, Loss:0.071739, Acc:100.0000\n",
      "Train: Epoch:31, Batch:279, Loss:0.269768, Acc:96.8750\n",
      "Train: Epoch:31, Batch:299, Loss:0.177800, Acc:96.8750\n",
      "Train: Epoch:31, Batch:319, Loss:0.186186, Acc:93.7500\n",
      "Train: Epoch:31, Batch:339, Loss:0.215475, Acc:93.7500\n",
      "Train: Epoch:31, Batch:359, Loss:0.115772, Acc:93.7500\n",
      "Train: Epoch:31, Batch:379, Loss:0.073975, Acc:96.8750\n",
      "Train: Epoch:31, Batch:399, Loss:0.181426, Acc:93.7500\n",
      "Train: Epoch:31, Batch:419, Loss:0.108009, Acc:93.7500\n",
      "Train: Epoch:31, Batch:439, Loss:0.081280, Acc:96.8750\n",
      "Train: Epoch:31, Batch:459, Loss:0.373968, Acc:87.5000\n",
      "Train: Epoch:31, Batch:479, Loss:0.236217, Acc:87.5000\n",
      "Train: Epoch:31, Batch:499, Loss:0.131964, Acc:93.7500\n",
      "Train: Epoch:31, Batch:519, Loss:0.111358, Acc:93.7500\n",
      "Train: Epoch:31, Batch:539, Loss:0.077482, Acc:96.8750\n",
      "Train: Epoch:31, Batch:559, Loss:0.114481, Acc:96.8750\n",
      "Train: Epoch:31, Batch:579, Loss:0.078499, Acc:96.8750\n",
      "Train: Epoch:31, Batch:599, Loss:0.132327, Acc:96.8750\n",
      "Train: Epoch:31, Batch:619, Loss:0.279783, Acc:87.5000\n",
      "Train: Epoch:31, Batch:639, Loss:0.171479, Acc:93.7500\n",
      "Train: Epoch:31, Batch:659, Loss:0.244233, Acc:87.5000\n",
      "Train: Epoch:31, Batch:679, Loss:0.084602, Acc:96.8750\n",
      "Train: Epoch:31, Batch:699, Loss:0.039131, Acc:96.8750\n",
      "Train: Epoch:31, Batch:719, Loss:0.094134, Acc:96.8750\n",
      "Train: Epoch:31, Batch:739, Loss:0.240327, Acc:87.5000\n",
      "Train_: Avg Training Loss: 0.147934, Avg Training Acc: 94.491667\n",
      "Val_: Total Validation Loss: 1.504300, Acc: 70.7375\n",
      "Test_: Total Testing Acc: 70.6250\n",
      "Time taken = 1992.3313 s\n",
      "\n",
      "Train: Epoch:32, Batch:19, Loss:0.082803, Acc:96.8750\n",
      "Train: Epoch:32, Batch:39, Loss:0.114516, Acc:96.8750\n",
      "Train: Epoch:32, Batch:59, Loss:0.137738, Acc:93.7500\n",
      "Train: Epoch:32, Batch:79, Loss:0.129931, Acc:93.7500\n",
      "Train: Epoch:32, Batch:99, Loss:0.065611, Acc:96.8750\n",
      "Train: Epoch:32, Batch:119, Loss:0.069177, Acc:96.8750\n",
      "Train: Epoch:32, Batch:139, Loss:0.033666, Acc:100.0000\n",
      "Train: Epoch:32, Batch:159, Loss:0.031003, Acc:100.0000\n",
      "Train: Epoch:32, Batch:179, Loss:0.050951, Acc:100.0000\n",
      "Train: Epoch:32, Batch:199, Loss:0.179255, Acc:93.7500\n",
      "Train: Epoch:32, Batch:219, Loss:0.054905, Acc:96.8750\n",
      "Train: Epoch:32, Batch:239, Loss:0.131259, Acc:90.6250\n",
      "Train: Epoch:32, Batch:259, Loss:0.097206, Acc:96.8750\n",
      "Train: Epoch:32, Batch:279, Loss:0.079446, Acc:96.8750\n",
      "Train: Epoch:32, Batch:299, Loss:0.232241, Acc:90.6250\n",
      "Train: Epoch:32, Batch:319, Loss:0.187752, Acc:96.8750\n",
      "Train: Epoch:32, Batch:339, Loss:0.086076, Acc:96.8750\n",
      "Train: Epoch:32, Batch:359, Loss:0.063753, Acc:96.8750\n",
      "Train: Epoch:32, Batch:379, Loss:0.129001, Acc:93.7500\n",
      "Train: Epoch:32, Batch:399, Loss:0.101879, Acc:93.7500\n",
      "Train: Epoch:32, Batch:419, Loss:0.128944, Acc:93.7500\n",
      "Train: Epoch:32, Batch:439, Loss:0.194897, Acc:96.8750\n",
      "Train: Epoch:32, Batch:459, Loss:0.097798, Acc:96.8750\n",
      "Train: Epoch:32, Batch:479, Loss:0.063990, Acc:96.8750\n",
      "Train: Epoch:32, Batch:499, Loss:0.083029, Acc:96.8750\n",
      "Train: Epoch:32, Batch:519, Loss:0.116477, Acc:93.7500\n",
      "Train: Epoch:32, Batch:539, Loss:0.113681, Acc:96.8750\n",
      "Train: Epoch:32, Batch:559, Loss:0.101018, Acc:96.8750\n",
      "Train: Epoch:32, Batch:579, Loss:0.046969, Acc:100.0000\n",
      "Train: Epoch:32, Batch:599, Loss:0.111611, Acc:96.8750\n",
      "Train: Epoch:32, Batch:619, Loss:0.103111, Acc:93.7500\n",
      "Train: Epoch:32, Batch:639, Loss:0.052861, Acc:96.8750\n",
      "Train: Epoch:32, Batch:659, Loss:0.067000, Acc:100.0000\n",
      "Train: Epoch:32, Batch:679, Loss:0.158255, Acc:93.7500\n",
      "Train: Epoch:32, Batch:699, Loss:0.243335, Acc:87.5000\n",
      "Train: Epoch:32, Batch:719, Loss:0.202322, Acc:93.7500\n",
      "Train: Epoch:32, Batch:739, Loss:0.143962, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.131306, Avg Training Acc: 95.204167\n",
      "Val_: Total Validation Loss: 1.454798, Acc: 71.4750\n",
      "Test_: Total Testing Acc: 71.4875\n",
      "Time taken = 1954.0382 s\n",
      "\n",
      "Train: Epoch:33, Batch:19, Loss:0.015474, Acc:100.0000\n",
      "Train: Epoch:33, Batch:39, Loss:0.078557, Acc:96.8750\n",
      "Train: Epoch:33, Batch:59, Loss:0.197515, Acc:96.8750\n",
      "Train: Epoch:33, Batch:79, Loss:0.085036, Acc:90.6250\n",
      "Train: Epoch:33, Batch:99, Loss:0.064817, Acc:96.8750\n",
      "Train: Epoch:33, Batch:119, Loss:0.091712, Acc:96.8750\n",
      "Train: Epoch:33, Batch:139, Loss:0.098509, Acc:93.7500\n",
      "Train: Epoch:33, Batch:159, Loss:0.078571, Acc:96.8750\n",
      "Train: Epoch:33, Batch:179, Loss:0.025520, Acc:100.0000\n",
      "Train: Epoch:33, Batch:199, Loss:0.101309, Acc:93.7500\n",
      "Train: Epoch:33, Batch:219, Loss:0.109677, Acc:93.7500\n",
      "Train: Epoch:33, Batch:239, Loss:0.087807, Acc:100.0000\n",
      "Train: Epoch:33, Batch:259, Loss:0.009604, Acc:100.0000\n",
      "Train: Epoch:33, Batch:279, Loss:0.204853, Acc:93.7500\n",
      "Train: Epoch:33, Batch:299, Loss:0.101702, Acc:100.0000\n",
      "Train: Epoch:33, Batch:319, Loss:0.152268, Acc:87.5000\n",
      "Train: Epoch:33, Batch:339, Loss:0.060360, Acc:96.8750\n",
      "Train: Epoch:33, Batch:359, Loss:0.292439, Acc:87.5000\n",
      "Train: Epoch:33, Batch:379, Loss:0.327128, Acc:90.6250\n",
      "Train: Epoch:33, Batch:399, Loss:0.099271, Acc:96.8750\n",
      "Train: Epoch:33, Batch:419, Loss:0.174128, Acc:90.6250\n",
      "Train: Epoch:33, Batch:439, Loss:0.160199, Acc:93.7500\n",
      "Train: Epoch:33, Batch:459, Loss:0.140459, Acc:96.8750\n",
      "Train: Epoch:33, Batch:479, Loss:0.102059, Acc:96.8750\n",
      "Train: Epoch:33, Batch:499, Loss:0.132127, Acc:93.7500\n",
      "Train: Epoch:33, Batch:519, Loss:0.121663, Acc:96.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:33, Batch:539, Loss:0.075230, Acc:100.0000\n",
      "Train: Epoch:33, Batch:559, Loss:0.192246, Acc:96.8750\n",
      "Train: Epoch:33, Batch:579, Loss:0.087482, Acc:96.8750\n",
      "Train: Epoch:33, Batch:599, Loss:0.101618, Acc:100.0000\n",
      "Train: Epoch:33, Batch:619, Loss:0.061027, Acc:96.8750\n",
      "Train: Epoch:33, Batch:639, Loss:0.090388, Acc:90.6250\n",
      "Train: Epoch:33, Batch:659, Loss:0.187766, Acc:90.6250\n",
      "Train: Epoch:33, Batch:679, Loss:0.105602, Acc:93.7500\n",
      "Train: Epoch:33, Batch:699, Loss:0.197296, Acc:93.7500\n",
      "Train: Epoch:33, Batch:719, Loss:0.076456, Acc:96.8750\n",
      "Train: Epoch:33, Batch:739, Loss:0.317078, Acc:93.7500\n",
      "Train_: Avg Training Loss: 0.131107, Avg Training Acc: 95.145833\n",
      "Val_: Total Validation Loss: 1.514687, Acc: 71.8250\n",
      "Test_: Total Testing Acc: 71.9875\n",
      "Time taken = 1957.9116 s\n",
      "\n",
      "Train: Epoch:34, Batch:19, Loss:0.113933, Acc:96.8750\n",
      "Train: Epoch:34, Batch:39, Loss:0.065536, Acc:100.0000\n",
      "Train: Epoch:34, Batch:59, Loss:0.160028, Acc:96.8750\n",
      "Train: Epoch:34, Batch:79, Loss:0.114250, Acc:96.8750\n",
      "Train: Epoch:34, Batch:99, Loss:0.019026, Acc:100.0000\n",
      "Train: Epoch:34, Batch:119, Loss:0.037331, Acc:100.0000\n",
      "Train: Epoch:34, Batch:139, Loss:0.060293, Acc:96.8750\n",
      "Train: Epoch:34, Batch:159, Loss:0.116029, Acc:93.7500\n",
      "Train: Epoch:34, Batch:179, Loss:0.070608, Acc:96.8750\n",
      "Train: Epoch:34, Batch:199, Loss:0.086452, Acc:96.8750\n",
      "Train: Epoch:34, Batch:219, Loss:0.154353, Acc:93.7500\n",
      "Train: Epoch:34, Batch:239, Loss:0.119781, Acc:93.7500\n",
      "Train: Epoch:34, Batch:259, Loss:0.063936, Acc:96.8750\n",
      "Train: Epoch:34, Batch:279, Loss:0.046795, Acc:100.0000\n",
      "Train: Epoch:34, Batch:299, Loss:0.098675, Acc:93.7500\n",
      "Train: Epoch:34, Batch:319, Loss:0.145944, Acc:96.8750\n",
      "Train: Epoch:34, Batch:339, Loss:0.114450, Acc:96.8750\n",
      "Train: Epoch:34, Batch:359, Loss:0.098748, Acc:96.8750\n",
      "Train: Epoch:34, Batch:379, Loss:0.364446, Acc:90.6250\n",
      "Train: Epoch:34, Batch:399, Loss:0.135008, Acc:93.7500\n",
      "Train: Epoch:34, Batch:419, Loss:0.165650, Acc:90.6250\n",
      "Train: Epoch:34, Batch:439, Loss:0.167974, Acc:96.8750\n",
      "Train: Epoch:34, Batch:459, Loss:0.053410, Acc:96.8750\n",
      "Train: Epoch:34, Batch:479, Loss:0.354894, Acc:90.6250\n",
      "Train: Epoch:34, Batch:499, Loss:0.132289, Acc:93.7500\n",
      "Train: Epoch:34, Batch:519, Loss:0.256487, Acc:93.7500\n",
      "Train: Epoch:34, Batch:539, Loss:0.268494, Acc:84.3750\n",
      "Train: Epoch:34, Batch:559, Loss:0.309359, Acc:87.5000\n",
      "Train: Epoch:34, Batch:579, Loss:0.339918, Acc:93.7500\n",
      "Train: Epoch:34, Batch:599, Loss:0.052631, Acc:100.0000\n",
      "Train: Epoch:34, Batch:619, Loss:0.016061, Acc:100.0000\n",
      "Train: Epoch:34, Batch:639, Loss:0.080662, Acc:100.0000\n",
      "Train: Epoch:34, Batch:659, Loss:0.229590, Acc:87.5000\n",
      "Train: Epoch:34, Batch:679, Loss:0.366660, Acc:90.6250\n",
      "Train: Epoch:34, Batch:699, Loss:0.482749, Acc:93.7500\n",
      "Train: Epoch:34, Batch:719, Loss:0.251666, Acc:87.5000\n",
      "Train: Epoch:34, Batch:739, Loss:0.261193, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.131035, Avg Training Acc: 95.212500\n",
      "Val_: Total Validation Loss: 1.517020, Acc: 70.9750\n",
      "Test_: Total Testing Acc: 71.0125\n",
      "Time taken = 2003.0301 s\n",
      "\n",
      "Train: Epoch:35, Batch:19, Loss:0.020551, Acc:100.0000\n",
      "Train: Epoch:35, Batch:39, Loss:0.075316, Acc:96.8750\n",
      "Train: Epoch:35, Batch:59, Loss:0.088915, Acc:96.8750\n",
      "Train: Epoch:35, Batch:79, Loss:0.159482, Acc:90.6250\n",
      "Train: Epoch:35, Batch:99, Loss:0.160614, Acc:93.7500\n",
      "Train: Epoch:35, Batch:119, Loss:0.162969, Acc:93.7500\n",
      "Train: Epoch:35, Batch:139, Loss:0.095306, Acc:96.8750\n",
      "Train: Epoch:35, Batch:159, Loss:0.248997, Acc:96.8750\n",
      "Train: Epoch:35, Batch:179, Loss:0.141325, Acc:93.7500\n",
      "Train: Epoch:35, Batch:199, Loss:0.038241, Acc:100.0000\n",
      "Train: Epoch:35, Batch:219, Loss:0.151815, Acc:96.8750\n",
      "Train: Epoch:35, Batch:239, Loss:0.195622, Acc:90.6250\n",
      "Train: Epoch:35, Batch:259, Loss:0.359925, Acc:93.7500\n",
      "Train: Epoch:35, Batch:279, Loss:0.037883, Acc:100.0000\n",
      "Train: Epoch:35, Batch:299, Loss:0.375176, Acc:96.8750\n",
      "Train: Epoch:35, Batch:319, Loss:0.164773, Acc:90.6250\n",
      "Train: Epoch:35, Batch:339, Loss:0.068497, Acc:100.0000\n",
      "Train: Epoch:35, Batch:359, Loss:0.200827, Acc:93.7500\n",
      "Train: Epoch:35, Batch:379, Loss:0.137608, Acc:93.7500\n",
      "Train: Epoch:35, Batch:399, Loss:0.142574, Acc:93.7500\n",
      "Train: Epoch:35, Batch:419, Loss:0.089965, Acc:96.8750\n",
      "Train: Epoch:35, Batch:439, Loss:0.117895, Acc:93.7500\n",
      "Train: Epoch:35, Batch:459, Loss:0.078942, Acc:96.8750\n",
      "Train: Epoch:35, Batch:479, Loss:0.086141, Acc:93.7500\n",
      "Train: Epoch:35, Batch:499, Loss:0.039143, Acc:100.0000\n",
      "Train: Epoch:35, Batch:519, Loss:0.143225, Acc:96.8750\n",
      "Train: Epoch:35, Batch:539, Loss:0.062369, Acc:100.0000\n",
      "Train: Epoch:35, Batch:559, Loss:0.132818, Acc:93.7500\n",
      "Train: Epoch:35, Batch:579, Loss:0.455832, Acc:90.6250\n",
      "Train: Epoch:35, Batch:599, Loss:0.089270, Acc:93.7500\n",
      "Train: Epoch:35, Batch:619, Loss:0.149908, Acc:93.7500\n",
      "Train: Epoch:35, Batch:639, Loss:0.025886, Acc:100.0000\n",
      "Train: Epoch:35, Batch:659, Loss:0.053013, Acc:96.8750\n",
      "Train: Epoch:35, Batch:679, Loss:0.079171, Acc:93.7500\n",
      "Train: Epoch:35, Batch:699, Loss:0.286650, Acc:90.6250\n",
      "Train: Epoch:35, Batch:719, Loss:0.361188, Acc:90.6250\n",
      "Train: Epoch:35, Batch:739, Loss:0.300831, Acc:90.6250\n",
      "Train_: Avg Training Loss: 0.140161, Avg Training Acc: 94.925000\n",
      "Val_: Total Validation Loss: 1.469890, Acc: 71.8000\n",
      "Test_: Total Testing Acc: 71.1500\n",
      "Time taken = 1985.7479 s\n",
      "\n",
      "Train: Epoch:36, Batch:19, Loss:0.218356, Acc:93.7500\n",
      "Train: Epoch:36, Batch:39, Loss:0.042965, Acc:100.0000\n",
      "Train: Epoch:36, Batch:59, Loss:0.032451, Acc:100.0000\n",
      "Train: Epoch:36, Batch:79, Loss:0.110448, Acc:93.7500\n",
      "Train: Epoch:36, Batch:99, Loss:0.080266, Acc:100.0000\n",
      "Train: Epoch:36, Batch:119, Loss:0.048189, Acc:100.0000\n",
      "Train: Epoch:36, Batch:139, Loss:0.151539, Acc:93.7500\n",
      "Train: Epoch:36, Batch:159, Loss:0.035375, Acc:100.0000\n",
      "Train: Epoch:36, Batch:179, Loss:0.024312, Acc:100.0000\n",
      "Train: Epoch:36, Batch:199, Loss:0.305567, Acc:90.6250\n",
      "Train: Epoch:36, Batch:219, Loss:0.142260, Acc:93.7500\n",
      "Train: Epoch:36, Batch:239, Loss:0.189638, Acc:87.5000\n",
      "Train: Epoch:36, Batch:259, Loss:0.019537, Acc:100.0000\n",
      "Train: Epoch:36, Batch:279, Loss:0.158702, Acc:90.6250\n",
      "Train: Epoch:36, Batch:299, Loss:0.391924, Acc:87.5000\n",
      "Train: Epoch:36, Batch:319, Loss:0.193713, Acc:90.6250\n",
      "Train: Epoch:36, Batch:339, Loss:0.194262, Acc:90.6250\n",
      "Train: Epoch:36, Batch:359, Loss:0.100443, Acc:96.8750\n",
      "Train: Epoch:36, Batch:379, Loss:0.172272, Acc:96.8750\n",
      "Train: Epoch:36, Batch:399, Loss:0.414332, Acc:93.7500\n",
      "Train: Epoch:36, Batch:419, Loss:0.374120, Acc:87.5000\n",
      "Train: Epoch:36, Batch:439, Loss:0.074521, Acc:100.0000\n",
      "Train: Epoch:36, Batch:459, Loss:0.092039, Acc:93.7500\n",
      "Train: Epoch:36, Batch:479, Loss:0.109135, Acc:96.8750\n",
      "Train: Epoch:36, Batch:499, Loss:0.171550, Acc:96.8750\n",
      "Train: Epoch:36, Batch:519, Loss:0.078875, Acc:93.7500\n",
      "Train: Epoch:36, Batch:539, Loss:0.160290, Acc:93.7500\n",
      "Train: Epoch:36, Batch:559, Loss:0.236148, Acc:87.5000\n",
      "Train: Epoch:36, Batch:579, Loss:0.047269, Acc:96.8750\n",
      "Train: Epoch:36, Batch:599, Loss:0.119199, Acc:93.7500\n",
      "Train: Epoch:36, Batch:619, Loss:0.189660, Acc:93.7500\n",
      "Train: Epoch:36, Batch:639, Loss:0.232884, Acc:93.7500\n",
      "Train: Epoch:36, Batch:659, Loss:0.179769, Acc:90.6250\n",
      "Train: Epoch:36, Batch:679, Loss:0.067855, Acc:96.8750\n",
      "Train: Epoch:36, Batch:699, Loss:0.097619, Acc:96.8750\n",
      "Train: Epoch:36, Batch:719, Loss:0.015448, Acc:100.0000\n",
      "Train: Epoch:36, Batch:739, Loss:0.075017, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.120287, Avg Training Acc: 95.566667\n",
      "Val_: Total Validation Loss: 1.483913, Acc: 71.3750\n",
      "Test_: Total Testing Acc: 71.5375\n",
      "Time taken = 1955.2944 s\n",
      "\n",
      "Train: Epoch:37, Batch:19, Loss:0.056859, Acc:96.8750\n",
      "Train: Epoch:37, Batch:39, Loss:0.077771, Acc:100.0000\n",
      "Train: Epoch:37, Batch:59, Loss:0.057876, Acc:96.8750\n",
      "Train: Epoch:37, Batch:79, Loss:0.119016, Acc:90.6250\n",
      "Train: Epoch:37, Batch:99, Loss:0.097698, Acc:96.8750\n",
      "Train: Epoch:37, Batch:119, Loss:0.028985, Acc:100.0000\n",
      "Train: Epoch:37, Batch:139, Loss:0.076429, Acc:96.8750\n",
      "Train: Epoch:37, Batch:159, Loss:0.187837, Acc:87.5000\n",
      "Train: Epoch:37, Batch:179, Loss:0.019118, Acc:100.0000\n",
      "Train: Epoch:37, Batch:199, Loss:0.138372, Acc:93.7500\n",
      "Train: Epoch:37, Batch:219, Loss:0.042086, Acc:96.8750\n",
      "Train: Epoch:37, Batch:239, Loss:0.193206, Acc:93.7500\n",
      "Train: Epoch:37, Batch:259, Loss:0.203373, Acc:93.7500\n",
      "Train: Epoch:37, Batch:279, Loss:0.295463, Acc:84.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:37, Batch:299, Loss:0.069275, Acc:100.0000\n",
      "Train: Epoch:37, Batch:319, Loss:0.159864, Acc:93.7500\n",
      "Train: Epoch:37, Batch:339, Loss:0.123273, Acc:93.7500\n",
      "Train: Epoch:37, Batch:359, Loss:0.157154, Acc:93.7500\n",
      "Train: Epoch:37, Batch:379, Loss:0.085143, Acc:96.8750\n",
      "Train: Epoch:37, Batch:399, Loss:0.232337, Acc:96.8750\n",
      "Train: Epoch:37, Batch:419, Loss:0.154679, Acc:93.7500\n",
      "Train: Epoch:37, Batch:439, Loss:0.024970, Acc:100.0000\n",
      "Train: Epoch:37, Batch:459, Loss:0.068161, Acc:96.8750\n",
      "Train: Epoch:37, Batch:479, Loss:0.080114, Acc:96.8750\n",
      "Train: Epoch:37, Batch:499, Loss:0.454843, Acc:96.8750\n",
      "Train: Epoch:37, Batch:519, Loss:0.045693, Acc:100.0000\n",
      "Train: Epoch:37, Batch:539, Loss:0.172166, Acc:96.8750\n",
      "Train: Epoch:37, Batch:559, Loss:0.136394, Acc:93.7500\n",
      "Train: Epoch:37, Batch:579, Loss:0.066865, Acc:100.0000\n",
      "Train: Epoch:37, Batch:599, Loss:0.363941, Acc:90.6250\n",
      "Train: Epoch:37, Batch:619, Loss:0.230858, Acc:93.7500\n",
      "Train: Epoch:37, Batch:639, Loss:0.106999, Acc:93.7500\n",
      "Train: Epoch:37, Batch:659, Loss:0.088739, Acc:93.7500\n",
      "Train: Epoch:37, Batch:679, Loss:0.103380, Acc:93.7500\n",
      "Train: Epoch:37, Batch:699, Loss:0.135066, Acc:96.8750\n",
      "Train: Epoch:37, Batch:719, Loss:0.361698, Acc:87.5000\n",
      "Train: Epoch:37, Batch:739, Loss:0.089674, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.120946, Avg Training Acc: 95.387500\n",
      "Val_: Total Validation Loss: 1.518228, Acc: 71.4250\n",
      "Test_: Total Testing Acc: 71.4500\n",
      "Time taken = 1964.6747 s\n",
      "\n",
      "Train: Epoch:38, Batch:19, Loss:0.053977, Acc:100.0000\n",
      "Train: Epoch:38, Batch:39, Loss:0.109138, Acc:96.8750\n",
      "Train: Epoch:38, Batch:59, Loss:0.043531, Acc:96.8750\n",
      "Train: Epoch:38, Batch:79, Loss:0.086973, Acc:96.8750\n",
      "Train: Epoch:38, Batch:99, Loss:0.078236, Acc:96.8750\n",
      "Train: Epoch:38, Batch:119, Loss:0.060719, Acc:96.8750\n",
      "Train: Epoch:38, Batch:139, Loss:0.076988, Acc:96.8750\n",
      "Train: Epoch:38, Batch:159, Loss:0.087149, Acc:93.7500\n",
      "Train: Epoch:38, Batch:179, Loss:0.168018, Acc:93.7500\n",
      "Train: Epoch:38, Batch:199, Loss:0.143653, Acc:93.7500\n",
      "Train: Epoch:38, Batch:219, Loss:0.250242, Acc:90.6250\n",
      "Train: Epoch:38, Batch:239, Loss:0.071661, Acc:100.0000\n",
      "Train: Epoch:38, Batch:259, Loss:0.103992, Acc:96.8750\n",
      "Train: Epoch:38, Batch:279, Loss:0.152691, Acc:93.7500\n",
      "Train: Epoch:38, Batch:299, Loss:0.100796, Acc:93.7500\n",
      "Train: Epoch:38, Batch:319, Loss:0.028198, Acc:100.0000\n",
      "Train: Epoch:38, Batch:339, Loss:0.173044, Acc:90.6250\n",
      "Train: Epoch:38, Batch:359, Loss:0.069368, Acc:96.8750\n",
      "Train: Epoch:38, Batch:379, Loss:0.136074, Acc:93.7500\n",
      "Train: Epoch:38, Batch:399, Loss:0.027794, Acc:100.0000\n",
      "Train: Epoch:38, Batch:419, Loss:0.113501, Acc:96.8750\n",
      "Train: Epoch:38, Batch:439, Loss:0.085823, Acc:96.8750\n",
      "Train: Epoch:38, Batch:459, Loss:0.056137, Acc:96.8750\n",
      "Train: Epoch:38, Batch:479, Loss:0.118571, Acc:96.8750\n",
      "Train: Epoch:38, Batch:499, Loss:0.028382, Acc:100.0000\n",
      "Train: Epoch:38, Batch:519, Loss:0.261842, Acc:90.6250\n",
      "Train: Epoch:38, Batch:539, Loss:0.142373, Acc:96.8750\n",
      "Train: Epoch:38, Batch:559, Loss:0.073985, Acc:100.0000\n",
      "Train: Epoch:38, Batch:579, Loss:0.042692, Acc:100.0000\n",
      "Train: Epoch:38, Batch:599, Loss:0.025812, Acc:100.0000\n",
      "Train: Epoch:38, Batch:619, Loss:0.066899, Acc:100.0000\n",
      "Train: Epoch:38, Batch:639, Loss:0.130690, Acc:90.6250\n",
      "Train: Epoch:38, Batch:659, Loss:0.133002, Acc:96.8750\n",
      "Train: Epoch:38, Batch:679, Loss:0.186948, Acc:90.6250\n",
      "Train: Epoch:38, Batch:699, Loss:0.322516, Acc:87.5000\n",
      "Train: Epoch:38, Batch:719, Loss:0.094773, Acc:96.8750\n",
      "Train: Epoch:38, Batch:739, Loss:0.022071, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.124792, Avg Training Acc: 95.420833\n",
      "Val_: Total Validation Loss: 1.535503, Acc: 71.6375\n",
      "Test_: Total Testing Acc: 71.3000\n",
      "Time taken = 2003.4738 s\n",
      "\n",
      "Train: Epoch:39, Batch:19, Loss:0.071813, Acc:96.8750\n",
      "Train: Epoch:39, Batch:39, Loss:0.106196, Acc:96.8750\n",
      "Train: Epoch:39, Batch:59, Loss:0.114506, Acc:93.7500\n",
      "Train: Epoch:39, Batch:79, Loss:0.048441, Acc:96.8750\n",
      "Train: Epoch:39, Batch:99, Loss:0.010017, Acc:100.0000\n",
      "Train: Epoch:39, Batch:119, Loss:0.091194, Acc:96.8750\n",
      "Train: Epoch:39, Batch:139, Loss:0.197916, Acc:96.8750\n",
      "Train: Epoch:39, Batch:159, Loss:0.236590, Acc:90.6250\n",
      "Train: Epoch:39, Batch:179, Loss:0.058474, Acc:96.8750\n",
      "Train: Epoch:39, Batch:199, Loss:0.126993, Acc:90.6250\n",
      "Train: Epoch:39, Batch:219, Loss:0.009659, Acc:100.0000\n",
      "Train: Epoch:39, Batch:239, Loss:0.068819, Acc:96.8750\n",
      "Train: Epoch:39, Batch:259, Loss:0.098526, Acc:96.8750\n",
      "Train: Epoch:39, Batch:279, Loss:0.197633, Acc:90.6250\n",
      "Train: Epoch:39, Batch:299, Loss:0.113355, Acc:93.7500\n",
      "Train: Epoch:39, Batch:319, Loss:0.015138, Acc:100.0000\n",
      "Train: Epoch:39, Batch:339, Loss:0.040066, Acc:100.0000\n",
      "Train: Epoch:39, Batch:359, Loss:0.289309, Acc:90.6250\n",
      "Train: Epoch:39, Batch:379, Loss:0.015697, Acc:100.0000\n",
      "Train: Epoch:39, Batch:399, Loss:0.264357, Acc:93.7500\n",
      "Train: Epoch:39, Batch:419, Loss:0.321911, Acc:90.6250\n",
      "Train: Epoch:39, Batch:439, Loss:0.455404, Acc:87.5000\n",
      "Train: Epoch:39, Batch:459, Loss:0.101352, Acc:93.7500\n",
      "Train: Epoch:39, Batch:479, Loss:0.350937, Acc:87.5000\n",
      "Train: Epoch:39, Batch:499, Loss:0.013174, Acc:100.0000\n",
      "Train: Epoch:39, Batch:519, Loss:0.239107, Acc:81.2500\n",
      "Train: Epoch:39, Batch:539, Loss:0.091639, Acc:96.8750\n",
      "Train: Epoch:39, Batch:559, Loss:0.127475, Acc:93.7500\n",
      "Train: Epoch:39, Batch:579, Loss:0.178128, Acc:93.7500\n",
      "Train: Epoch:39, Batch:599, Loss:0.125643, Acc:96.8750\n",
      "Train: Epoch:39, Batch:619, Loss:0.150444, Acc:96.8750\n",
      "Train: Epoch:39, Batch:639, Loss:0.126829, Acc:96.8750\n",
      "Train: Epoch:39, Batch:659, Loss:0.044127, Acc:100.0000\n",
      "Train: Epoch:39, Batch:679, Loss:0.077592, Acc:96.8750\n",
      "Train: Epoch:39, Batch:699, Loss:0.045924, Acc:96.8750\n",
      "Train: Epoch:39, Batch:719, Loss:0.317599, Acc:90.6250\n",
      "Train: Epoch:39, Batch:739, Loss:0.060220, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.138566, Avg Training Acc: 94.929167\n",
      "Val_: Total Validation Loss: 1.515146, Acc: 71.0875\n",
      "Test_: Total Testing Acc: 70.4750\n",
      "Time taken = 1956.6165 s\n",
      "\n",
      "Train: Epoch:40, Batch:19, Loss:0.072526, Acc:96.8750\n",
      "Train: Epoch:40, Batch:39, Loss:0.090316, Acc:93.7500\n",
      "Train: Epoch:40, Batch:59, Loss:0.027507, Acc:100.0000\n",
      "Train: Epoch:40, Batch:79, Loss:0.077924, Acc:100.0000\n",
      "Train: Epoch:40, Batch:99, Loss:0.148014, Acc:90.6250\n",
      "Train: Epoch:40, Batch:119, Loss:0.122601, Acc:93.7500\n",
      "Train: Epoch:40, Batch:139, Loss:0.059510, Acc:100.0000\n",
      "Train: Epoch:40, Batch:159, Loss:0.102982, Acc:100.0000\n",
      "Train: Epoch:40, Batch:179, Loss:0.064339, Acc:96.8750\n",
      "Train: Epoch:40, Batch:199, Loss:0.120271, Acc:96.8750\n",
      "Train: Epoch:40, Batch:219, Loss:0.042409, Acc:100.0000\n",
      "Train: Epoch:40, Batch:239, Loss:0.064964, Acc:93.7500\n",
      "Train: Epoch:40, Batch:259, Loss:0.161750, Acc:90.6250\n",
      "Train: Epoch:40, Batch:279, Loss:0.088917, Acc:96.8750\n",
      "Train: Epoch:40, Batch:299, Loss:0.129277, Acc:96.8750\n",
      "Train: Epoch:40, Batch:319, Loss:0.153277, Acc:93.7500\n",
      "Train: Epoch:40, Batch:339, Loss:0.022705, Acc:100.0000\n",
      "Train: Epoch:40, Batch:359, Loss:0.135151, Acc:93.7500\n",
      "Train: Epoch:40, Batch:379, Loss:0.373352, Acc:96.8750\n",
      "Train: Epoch:40, Batch:399, Loss:0.180945, Acc:90.6250\n",
      "Train: Epoch:40, Batch:419, Loss:0.080390, Acc:93.7500\n",
      "Train: Epoch:40, Batch:439, Loss:0.088101, Acc:96.8750\n",
      "Train: Epoch:40, Batch:459, Loss:0.034812, Acc:100.0000\n",
      "Train: Epoch:40, Batch:479, Loss:0.080628, Acc:96.8750\n",
      "Train: Epoch:40, Batch:499, Loss:0.065677, Acc:96.8750\n",
      "Train: Epoch:40, Batch:519, Loss:0.057159, Acc:93.7500\n",
      "Train: Epoch:40, Batch:539, Loss:0.120514, Acc:96.8750\n",
      "Train: Epoch:40, Batch:559, Loss:0.053109, Acc:100.0000\n",
      "Train: Epoch:40, Batch:579, Loss:0.140612, Acc:96.8750\n",
      "Train: Epoch:40, Batch:599, Loss:0.008884, Acc:100.0000\n",
      "Train: Epoch:40, Batch:619, Loss:0.088878, Acc:96.8750\n",
      "Train: Epoch:40, Batch:639, Loss:0.097431, Acc:96.8750\n",
      "Train: Epoch:40, Batch:659, Loss:0.229782, Acc:93.7500\n",
      "Train: Epoch:40, Batch:679, Loss:0.128954, Acc:96.8750\n",
      "Train: Epoch:40, Batch:699, Loss:0.108733, Acc:96.8750\n",
      "Train: Epoch:40, Batch:719, Loss:0.136330, Acc:93.7500\n",
      "Train: Epoch:40, Batch:739, Loss:0.069484, Acc:96.8750\n",
      "Train_: Avg Training Loss: 0.114646, Avg Training Acc: 95.829167\n",
      "Val_: Total Validation Loss: 1.484478, Acc: 71.8125\n",
      "Test_: Total Testing Acc: 71.6500\n",
      "Time taken = 1961.2723 s\n",
      "\n",
      "Train: Epoch:41, Batch:19, Loss:0.119820, Acc:93.7500\n",
      "Train: Epoch:41, Batch:39, Loss:0.132439, Acc:90.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch:41, Batch:59, Loss:0.066985, Acc:96.8750\n",
      "Train: Epoch:41, Batch:79, Loss:0.021774, Acc:100.0000\n",
      "Train: Epoch:41, Batch:99, Loss:0.248450, Acc:90.6250\n",
      "Train: Epoch:41, Batch:119, Loss:0.094590, Acc:96.8750\n",
      "Train: Epoch:41, Batch:139, Loss:0.116728, Acc:96.8750\n",
      "Train: Epoch:41, Batch:159, Loss:0.192431, Acc:93.7500\n",
      "Train: Epoch:41, Batch:179, Loss:0.205406, Acc:90.6250\n",
      "Train: Epoch:41, Batch:199, Loss:0.028106, Acc:100.0000\n",
      "Train: Epoch:41, Batch:219, Loss:0.145676, Acc:96.8750\n",
      "Train: Epoch:41, Batch:239, Loss:0.099538, Acc:96.8750\n",
      "Train: Epoch:41, Batch:259, Loss:0.091636, Acc:93.7500\n",
      "Train: Epoch:41, Batch:279, Loss:0.120847, Acc:96.8750\n",
      "Train: Epoch:41, Batch:299, Loss:0.006287, Acc:100.0000\n",
      "Train: Epoch:41, Batch:319, Loss:0.139299, Acc:96.8750\n",
      "Train: Epoch:41, Batch:339, Loss:0.025027, Acc:100.0000\n",
      "Train: Epoch:41, Batch:359, Loss:0.068495, Acc:100.0000\n",
      "Train: Epoch:41, Batch:379, Loss:0.198013, Acc:93.7500\n",
      "Train: Epoch:41, Batch:399, Loss:0.008581, Acc:100.0000\n",
      "Train: Epoch:41, Batch:419, Loss:0.107567, Acc:100.0000\n",
      "Train: Epoch:41, Batch:439, Loss:0.032661, Acc:100.0000\n",
      "Train: Epoch:41, Batch:459, Loss:0.219319, Acc:90.6250\n",
      "Train: Epoch:41, Batch:479, Loss:0.049383, Acc:96.8750\n",
      "Train: Epoch:41, Batch:499, Loss:0.060349, Acc:100.0000\n",
      "Train: Epoch:41, Batch:519, Loss:0.143662, Acc:93.7500\n",
      "Train: Epoch:41, Batch:539, Loss:0.188379, Acc:93.7500\n",
      "Train: Epoch:41, Batch:559, Loss:0.185661, Acc:90.6250\n",
      "Train: Epoch:41, Batch:579, Loss:0.678011, Acc:87.5000\n",
      "Train: Epoch:41, Batch:599, Loss:0.136041, Acc:96.8750\n",
      "Train: Epoch:41, Batch:619, Loss:0.132040, Acc:90.6250\n",
      "Train: Epoch:41, Batch:639, Loss:0.114312, Acc:93.7500\n",
      "Train: Epoch:41, Batch:659, Loss:0.258971, Acc:93.7500\n",
      "Train: Epoch:41, Batch:679, Loss:0.143373, Acc:90.6250\n",
      "Train: Epoch:41, Batch:699, Loss:0.130252, Acc:90.6250\n",
      "Train: Epoch:41, Batch:719, Loss:0.134920, Acc:96.8750\n",
      "Train: Epoch:41, Batch:739, Loss:0.317951, Acc:81.2500\n",
      "Train_: Avg Training Loss: 0.135840, Avg Training Acc: 95.141667\n",
      "Val_: Total Validation Loss: 1.520694, Acc: 71.2375\n",
      "Test_: Total Testing Acc: 71.0250\n",
      "Time taken = 2001.4530 s\n",
      "\n",
      "Train: Epoch:42, Batch:19, Loss:0.075939, Acc:96.8750\n",
      "Train: Epoch:42, Batch:39, Loss:0.058627, Acc:96.8750\n",
      "Train: Epoch:42, Batch:59, Loss:0.353605, Acc:90.6250\n",
      "Train: Epoch:42, Batch:79, Loss:0.066654, Acc:100.0000\n",
      "Train: Epoch:42, Batch:99, Loss:0.196734, Acc:90.6250\n",
      "Train: Epoch:42, Batch:119, Loss:0.274659, Acc:87.5000\n",
      "Train: Epoch:42, Batch:139, Loss:0.094893, Acc:96.8750\n",
      "Train: Epoch:42, Batch:159, Loss:0.074566, Acc:96.8750\n",
      "Train: Epoch:42, Batch:179, Loss:0.068885, Acc:93.7500\n",
      "Train: Epoch:42, Batch:199, Loss:0.033991, Acc:100.0000\n",
      "Train: Epoch:42, Batch:219, Loss:0.100489, Acc:96.8750\n",
      "Train: Epoch:42, Batch:239, Loss:0.023999, Acc:100.0000\n",
      "Train: Epoch:42, Batch:259, Loss:0.100930, Acc:100.0000\n",
      "Train: Epoch:42, Batch:279, Loss:0.035615, Acc:100.0000\n",
      "Train: Epoch:42, Batch:299, Loss:0.129689, Acc:93.7500\n",
      "Train: Epoch:42, Batch:319, Loss:0.100989, Acc:100.0000\n",
      "Train: Epoch:42, Batch:339, Loss:0.274983, Acc:87.5000\n",
      "Train: Epoch:42, Batch:359, Loss:0.046981, Acc:96.8750\n",
      "Train: Epoch:42, Batch:379, Loss:0.079533, Acc:100.0000\n",
      "Train: Epoch:42, Batch:399, Loss:0.092084, Acc:96.8750\n",
      "Train: Epoch:42, Batch:419, Loss:0.065991, Acc:96.8750\n",
      "Train: Epoch:42, Batch:439, Loss:0.058289, Acc:96.8750\n",
      "Train: Epoch:42, Batch:459, Loss:0.134448, Acc:93.7500\n",
      "Train: Epoch:42, Batch:479, Loss:0.263530, Acc:93.7500\n",
      "Train: Epoch:42, Batch:499, Loss:0.240119, Acc:96.8750\n",
      "Train: Epoch:42, Batch:519, Loss:0.082802, Acc:96.8750\n",
      "Train: Epoch:42, Batch:539, Loss:0.011710, Acc:100.0000\n",
      "Train: Epoch:42, Batch:559, Loss:0.095794, Acc:96.8750\n",
      "Train: Epoch:42, Batch:579, Loss:0.115123, Acc:93.7500\n",
      "Train: Epoch:42, Batch:599, Loss:0.040363, Acc:100.0000\n",
      "Train: Epoch:42, Batch:619, Loss:0.155318, Acc:96.8750\n",
      "Train: Epoch:42, Batch:639, Loss:0.066909, Acc:100.0000\n",
      "Train: Epoch:42, Batch:659, Loss:0.210396, Acc:87.5000\n",
      "Train: Epoch:42, Batch:679, Loss:0.134934, Acc:93.7500\n",
      "Train: Epoch:42, Batch:699, Loss:0.196918, Acc:87.5000\n",
      "Train: Epoch:42, Batch:719, Loss:0.254003, Acc:93.7500\n",
      "Train: Epoch:42, Batch:739, Loss:0.080403, Acc:100.0000\n",
      "Train_: Avg Training Loss: 0.109012, Avg Training Acc: 96.141667\n",
      "Val_: Total Validation Loss: 1.579100, Acc: 71.8125\n",
      "Test_: Total Testing Acc: 71.5125\n",
      "Time taken = 2064.5821 s\n",
      "\n",
      "Train: Epoch:43, Batch:19, Loss:0.276982, Acc:93.7500\n",
      "Train: Epoch:43, Batch:39, Loss:0.032038, Acc:100.0000\n",
      "Train: Epoch:43, Batch:59, Loss:0.129953, Acc:100.0000\n",
      "Train: Epoch:43, Batch:79, Loss:0.104450, Acc:93.7500\n",
      "Train: Epoch:43, Batch:99, Loss:0.102200, Acc:96.8750\n",
      "Train: Epoch:43, Batch:119, Loss:0.469305, Acc:93.7500\n",
      "Train: Epoch:43, Batch:139, Loss:0.017943, Acc:100.0000\n",
      "Train: Epoch:43, Batch:159, Loss:0.244223, Acc:93.7500\n",
      "Train: Epoch:43, Batch:179, Loss:0.144267, Acc:96.8750\n",
      "Train: Epoch:43, Batch:199, Loss:0.057424, Acc:100.0000\n",
      "Train: Epoch:43, Batch:219, Loss:0.087654, Acc:93.7500\n",
      "Train: Epoch:43, Batch:239, Loss:0.032738, Acc:100.0000\n",
      "Train: Epoch:43, Batch:259, Loss:0.022588, Acc:100.0000\n",
      "Train: Epoch:43, Batch:279, Loss:0.123312, Acc:93.7500\n",
      "Train: Epoch:43, Batch:299, Loss:0.034206, Acc:100.0000\n",
      "Train: Epoch:43, Batch:319, Loss:0.138890, Acc:96.8750\n",
      "Train: Epoch:43, Batch:339, Loss:0.067666, Acc:100.0000\n",
      "Train: Epoch:43, Batch:359, Loss:0.070511, Acc:96.8750\n",
      "Train: Epoch:43, Batch:379, Loss:0.129059, Acc:90.6250\n",
      "Train: Epoch:43, Batch:399, Loss:0.377808, Acc:84.3750\n",
      "Train: Epoch:43, Batch:419, Loss:0.083346, Acc:96.8750\n",
      "Train: Epoch:43, Batch:439, Loss:0.295204, Acc:90.6250\n",
      "Train: Epoch:43, Batch:459, Loss:0.050827, Acc:96.8750\n",
      "Train: Epoch:43, Batch:479, Loss:0.115146, Acc:93.7500\n",
      "Train: Epoch:43, Batch:499, Loss:0.067691, Acc:96.8750\n",
      "Train: Epoch:43, Batch:519, Loss:0.313273, Acc:87.5000\n",
      "Train: Epoch:43, Batch:539, Loss:0.157492, Acc:93.7500\n"
     ]
    }
   ],
   "source": [
    "SAVE_FILE = \"ViTSCL_take2_ep82\" + time.strftime(\"%Y-%m-%d_%H:%M:%S\", time.gmtime()) + \"_\" + str(args.perc_train)\n",
    "\n",
    "for epoch in range(0, args.epochs):\n",
    "    t0 = time.time()\n",
    "    train(epoch, SAVE_FILE)\n",
    "    avg_loss, avg_acc = validate(epoch, SAVE_FILE)\n",
    "    test_acc = test(epoch, SAVE_FILE)\n",
    "    model.save_model(args.save, epoch, avg_acc, avg_loss)\n",
    "    print(\"Time taken = {:.4f} s\\n\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c36042",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62888399",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_single_fnames = [x for x in testset.file_names if '/center_single/' in x]\n",
    "distribute_four_fnames = [x for x in testset.file_names if '/distribute_four/' in x]\n",
    "in_distribute_four_out_center_single_fnames = \\\n",
    "    [x for x in testset.file_names if '/in_distribute_four_out_center_single/' in x]\n",
    "left_center_single_right_center_single_fnames = \\\n",
    "    [x for x in testset.file_names if '/left_center_single_right_center_single/' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d2592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_set = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "cs_set.file_names = center_single_fnames\n",
    "cs_testloader = DataLoader(cs_set, batch_size=args.batch_size, shuffle=False, num_workers=80)\n",
    "\n",
    "df_set = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "df_set.file_names = distribute_four_fnames\n",
    "df_testloader = DataLoader(df_set, batch_size=args.batch_size, shuffle=False, num_workers=80)\n",
    "\n",
    "idfo_set = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "idfo_set.file_names = in_distribute_four_out_center_single_fnames\n",
    "idfo_testloader = DataLoader(idfo_set, batch_size=args.batch_size, shuffle=False, num_workers=80)\n",
    "\n",
    "lcsr_set = dataset(args.path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "lcsr_set.file_names = left_center_single_right_center_single_fnames\n",
    "lcsr_testloader = DataLoader(lcsr_set, batch_size=args.batch_size, shuffle=False, num_workers=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15eccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sep(epoch, tl, save_file):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target, meta_structure, embedding, indicator) in enumerate(tl):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "            meta_structure = meta_structure.cuda()\n",
    "            embedding = embedding.cuda()\n",
    "            indicator = indicator.cuda()\n",
    "        acc = model.test_(image, target, meta_target, meta_structure, embedding, indicator)\n",
    "        # print('Test: Epoch:{}, Batch:{}, Acc:{:.4f}.'.format(epoch, batch_idx, acc))  \n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        save_str = \"Test_: Total Testing Acc: {:.4f}\".format(acc_all / float(counter))\n",
    "        print(save_str)\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write(save_str + \"\\n\")\n",
    "    return acc_all/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803c1064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_: Total Testing Acc: 93.6012\n",
      "Test_: Total Testing Acc: 72.7679\n",
      "Test_: Total Testing Acc: 66.7163\n",
      "Test_: Total Testing Acc: 53.0258\n"
     ]
    }
   ],
   "source": [
    "SAVE_FILE_SEP = SAVE_FILE + \"_sep\"\n",
    "\n",
    "test_acc_cs = test_sep(epoch, cs_testloader, SAVE_FILE_SEP)\n",
    "test_acc_df = test_sep(epoch, df_testloader, SAVE_FILE_SEP)\n",
    "test_acc_idfo = test_sep(epoch, idfo_testloader, SAVE_FILE_SEP)\n",
    "test_acc_lcsr = test_sep(epoch, lcsr_testloader, SAVE_FILE_SEP)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9efb524e"
   ],
   "name": "Experiments-with-ViT+SCL-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
